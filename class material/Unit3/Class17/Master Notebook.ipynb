{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pickling\n",
    "\n",
    " - technique that allows you to serialize and export your models (or any other data)\n",
    " - useful way to store your work after long training jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# import model, define X & y\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('../Data/housing.csv')\n",
    "X  = df.iloc[:, :-1]\n",
    "y  = df['PRICE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize model & fit\n",
    "lasso = Lasso()\n",
    "lasso.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# this will allow us to export our model and re-use it elsewhere\n",
    "# see the other untitled notebook to see how you import it\n",
    "import pickle\n",
    "\n",
    "with open('mod.pkl', 'wb') as mod:\n",
    "    pickle.dump(lasso, mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grid Search \n",
    "\n",
    " - way to use brute force to search for all parameters of your model\n",
    " - useful step to use after EDA and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# load in GridSearch module, and RandomForest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# this dictionary contains values to test for each parameter, which is listed as a key\n",
    "grid_params = {\n",
    "    'max_features': [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'min_samples_leaf': [1, 5, 10, 25, 50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize, and check params\n",
    "rfc = RandomForestRegressor(n_jobs=-1)\n",
    "rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# arguments:  estimators to use, number of folds for cross_validation, and your dictionary w/ \n",
    "# parameters\n",
    "Grid = GridSearchCV(estimator=rfc, cv=5, param_grid=grid_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jonat\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_features': [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8], 'n_estimators': [10, 50, 100], 'min_samples_leaf': [1, 5, 10, 25, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And fit -- this could take awhile!\n",
    "Grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 0.4, 'min_samples_leaf': 5, 'n_estimators': 10}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will return the parameters that gave the best results\n",
    "Grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jonat\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Jonat\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Jonat\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Jonat\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Jonat\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Jonat\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Jonat\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.83724227, 0.21048903, 0.22969542, 0.06480899, 0.16377511,\n",
       "        0.25801964, 0.0668108 , 0.18093004, 0.20382123, 0.06317234,\n",
       "        0.13835578, 0.18642378, 0.06598787, 0.15194135, 0.19569345,\n",
       "        0.05262017, 0.18184648, 0.25064316, 0.0640862 , 0.18930268,\n",
       "        0.24073834, 0.06876965, 0.19414353, 0.22572904, 0.06597981,\n",
       "        0.17895441, 0.21836796, 0.08984704, 0.22968621, 0.29385047,\n",
       "        0.07965517, 0.23717022, 0.26549172, 0.07577343, 0.20302234,\n",
       "        0.22279639, 0.07743554, 0.18238649, 0.22910647, 0.06780834,\n",
       "        0.15225301, 0.19405203, 0.06445837, 0.17473865, 0.22171121,\n",
       "        0.07068963, 0.2049458 , 0.25469198, 0.07188663, 0.20834742,\n",
       "        0.26323943, 0.07095633, 0.17486358, 0.23054523, 0.06065135,\n",
       "        0.17780991, 0.2877068 , 0.06567936, 0.18698754, 0.21966581,\n",
       "        0.07330737, 0.2612042 , 0.30930934, 0.07570605, 0.20277629,\n",
       "        0.24231257, 0.08063164, 0.22189975, 0.26993065, 0.08141913,\n",
       "        0.19868975, 0.25981455, 0.06468725, 0.1823555 , 0.21752844,\n",
       "        0.07532644, 0.24096346, 0.28397813, 0.07431026, 0.20209332,\n",
       "        0.28432884, 0.07595396, 0.20639591, 0.23610573, 0.09271121,\n",
       "        0.20125065, 0.26538973, 0.07318549, 0.18886347, 0.21163058,\n",
       "        0.06791935, 0.19620667, 0.28655562, 0.06171608, 0.21405611,\n",
       "        0.2460495 , 0.07479458, 0.196627  , 0.23091445, 0.05660143,\n",
       "        0.17057171, 0.2241003 , 0.06513042, 0.20295053, 0.28613424]),\n",
       " 'std_fit_time': array([1.53266199e+00, 1.07720577e-02, 9.90324079e-03, 1.67086457e-02,\n",
       "        2.79249698e-02, 4.04804559e-02, 7.53657700e-03, 3.38751868e-02,\n",
       "        1.41912481e-02, 1.36259087e-03, 3.00997446e-02, 3.05652724e-02,\n",
       "        1.16061601e-03, 4.79085830e-03, 1.41116071e-02, 5.97935780e-03,\n",
       "        1.30121923e-02, 2.59605295e-02, 1.39228373e-02, 1.07061925e-02,\n",
       "        3.24386403e-02, 3.52829739e-03, 1.64056632e-02, 2.40029259e-02,\n",
       "        3.49308379e-03, 1.95503989e-02, 1.04671762e-02, 9.64732217e-03,\n",
       "        3.72990188e-02, 5.09670591e-02, 1.02178293e-02, 4.19402207e-02,\n",
       "        3.97808501e-02, 7.41862783e-03, 2.22952943e-02, 1.07844897e-02,\n",
       "        4.84814493e-03, 2.75200395e-02, 1.13065499e-02, 1.09801672e-02,\n",
       "        2.74550938e-02, 2.58612382e-02, 1.71164037e-02, 8.45420223e-03,\n",
       "        1.38600121e-02, 5.24301694e-03, 1.41639926e-02, 1.25981380e-02,\n",
       "        5.51834734e-03, 2.21025183e-02, 3.08752346e-02, 4.35656375e-03,\n",
       "        1.21454972e-02, 1.07455417e-02, 1.19137048e-02, 3.64244419e-02,\n",
       "        6.86409161e-02, 3.50626546e-03, 5.56388885e-02, 2.43184856e-02,\n",
       "        2.17255920e-02, 3.04509999e-02, 4.53589382e-02, 1.32367619e-02,\n",
       "        6.43478112e-03, 6.61711039e-03, 6.92413407e-03, 4.57853962e-02,\n",
       "        5.50220183e-02, 1.30712340e-02, 3.78406303e-02, 4.25778438e-02,\n",
       "        1.35144250e-02, 1.53532042e-02, 2.04652257e-02, 9.28665827e-03,\n",
       "        3.16149207e-02, 2.44613944e-02, 3.36792520e-03, 3.02053731e-02,\n",
       "        3.12108849e-02, 8.68707924e-03, 3.03448691e-02, 1.71348267e-02,\n",
       "        8.14826967e-03, 4.51442091e-02, 6.51042705e-02, 2.62782927e-02,\n",
       "        1.67293352e-02, 9.27854099e-03, 5.16925949e-03, 8.33488430e-03,\n",
       "        2.85708839e-02, 1.87311881e-02, 2.00307716e-02, 1.66949875e-02,\n",
       "        1.80834481e-02, 6.28983408e-02, 1.84458808e-02, 1.51500550e-02,\n",
       "        2.05876190e-02, 1.03792160e-02, 3.08454926e-03, 3.17015746e-02,\n",
       "        8.70116771e-02]),\n",
       " 'mean_score_time': array([0.13725257, 0.12410884, 0.11832089, 0.1236064 , 0.12021842,\n",
       "        0.11512365, 0.12449393, 0.12503142, 0.11814313, 0.11527443,\n",
       "        0.11810541, 0.11338253, 0.12035728, 0.12533755, 0.12030973,\n",
       "        0.12920108, 0.11275525, 0.11647263, 0.114012  , 0.1190959 ,\n",
       "        0.11739402, 0.12697096, 0.12412758, 0.11453872, 0.11820168,\n",
       "        0.11622238, 0.11365657, 0.12559719, 0.11664538, 0.11743979,\n",
       "        0.12208757, 0.12423902, 0.11495824, 0.12757854, 0.12012978,\n",
       "        0.11430011, 0.12307835, 0.12062225, 0.11640334, 0.12436013,\n",
       "        0.12061782, 0.12429295, 0.12005811, 0.11243949, 0.11470928,\n",
       "        0.12143726, 0.12012129, 0.11528945, 0.11975508, 0.11513505,\n",
       "        0.12636805, 0.1221993 , 0.11322684, 0.11459742, 0.11529055,\n",
       "        0.11548686, 0.11109309, 0.11691036, 0.11709452, 0.11259212,\n",
       "        0.11397743, 0.11682425, 0.11783319, 0.12615027, 0.11465716,\n",
       "        0.11580105, 0.12017827, 0.1172174 , 0.1131989 , 0.11648479,\n",
       "        0.11510115, 0.11796947, 0.12147255, 0.12118969, 0.11940751,\n",
       "        0.12914352, 0.12296329, 0.12264566, 0.11554232, 0.11791778,\n",
       "        0.11452484, 0.13020744, 0.11763835, 0.12301836, 0.117769  ,\n",
       "        0.11354713, 0.11857705, 0.1209599 , 0.1211225 , 0.1140667 ,\n",
       "        0.1230104 , 0.11458616, 0.1130075 , 0.11483192, 0.12261519,\n",
       "        0.11206493, 0.12045727, 0.11915374, 0.12367673, 0.12049356,\n",
       "        0.11793218, 0.11594143, 0.11542349, 0.11745753, 0.115346  ]),\n",
       " 'std_score_time': array([0.0473546 , 0.00787517, 0.00671356, 0.00861112, 0.00210472,\n",
       "        0.00295027, 0.00787381, 0.00729132, 0.00544608, 0.00177978,\n",
       "        0.01083182, 0.00283025, 0.00389031, 0.00901535, 0.00697244,\n",
       "        0.00831227, 0.00228255, 0.00512956, 0.00249331, 0.00780989,\n",
       "        0.00933795, 0.00654285, 0.01015505, 0.00405815, 0.00272249,\n",
       "        0.00201633, 0.00603637, 0.00689998, 0.00316482, 0.00607689,\n",
       "        0.00500394, 0.00267147, 0.00260306, 0.01275796, 0.00717606,\n",
       "        0.00200985, 0.00811957, 0.00482684, 0.00547558, 0.00822797,\n",
       "        0.00677214, 0.0080432 , 0.00407613, 0.00332383, 0.00610887,\n",
       "        0.00551136, 0.00755691, 0.00689636, 0.00657255, 0.00571825,\n",
       "        0.00309037, 0.00768381, 0.00242848, 0.00207095, 0.00505774,\n",
       "        0.00379931, 0.00225676, 0.00335335, 0.00579409, 0.0036067 ,\n",
       "        0.00426879, 0.00536616, 0.00748535, 0.00695029, 0.00154136,\n",
       "        0.00566871, 0.00402438, 0.00269355, 0.00182046, 0.00149938,\n",
       "        0.00377732, 0.00419411, 0.00412028, 0.00885889, 0.00965423,\n",
       "        0.0072081 , 0.00988683, 0.00884387, 0.00194311, 0.0085168 ,\n",
       "        0.00206332, 0.00517598, 0.00329504, 0.00851939, 0.00111651,\n",
       "        0.00554047, 0.00912282, 0.00931564, 0.00702421, 0.00185799,\n",
       "        0.00426332, 0.00084535, 0.00264719, 0.00241126, 0.00676199,\n",
       "        0.00171601, 0.00490094, 0.00936093, 0.00681464, 0.00830525,\n",
       "        0.0063284 , 0.00704719, 0.0025763 , 0.00388938, 0.00545193]),\n",
       " 'param_max_features': masked_array(data=[0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.4, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
       "                    0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 5, 5, 5, 10, 10, 10, 25, 25, 25, 50, 50, 50,\n",
       "                    1, 1, 1, 5, 5, 5, 10, 10, 10, 25, 25, 25, 50, 50, 50,\n",
       "                    1, 1, 1, 5, 5, 5, 10, 10, 10, 25, 25, 25, 50, 50, 50,\n",
       "                    1, 1, 1, 5, 5, 5, 10, 10, 10, 25, 25, 25, 50, 50, 50,\n",
       "                    1, 1, 1, 5, 5, 5, 10, 10, 10, 25, 25, 25, 50, 50, 50,\n",
       "                    1, 1, 1, 5, 5, 5, 10, 10, 10, 25, 25, 25, 50, 50, 50,\n",
       "                    1, 1, 1, 5, 5, 5, 10, 10, 10, 25, 25, 25, 50, 50, 50],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10,\n",
       "                    50, 100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50,\n",
       "                    100, 10, 50, 100, 10, 50, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_features': 0.2, 'min_samples_leaf': 1, 'n_estimators': 10},\n",
       "  {'max_features': 0.2, 'min_samples_leaf': 1, 'n_estimators': 50},\n",
       "  {'max_features': 0.2, 'min_samples_leaf': 1, 'n_estimators': 100},\n",
       "  {'max_features': 0.2, 'min_samples_leaf': 5, 'n_estimators': 10},\n",
       "  {'max_features': 0.2, 'min_samples_leaf': 5, 'n_estimators': 50},\n",
       "  {'max_features': 0.2, 'min_samples_leaf': 5, 'n_estimators': 100},\n",
       "  {'max_features': 0.2, 'min_samples_leaf': 10, 'n_estimators': 10},\n",
       "  {'max_features': 0.2, 'min_samples_leaf': 10, 'n_estimators': 50},\n",
       "  {'max_features': 0.2, 'min_samples_leaf': 10, 'n_estimators': 100},\n",
       "  {'max_features': 0.2, 'min_samples_leaf': 25, 'n_estimators': 10},\n",
       "  {'max_features': 0.2, 'min_samples_leaf': 25, 'n_estimators': 50},\n",
       "  {'max_features': 0.2, 'min_samples_leaf': 25, 'n_estimators': 100},\n",
       "  {'max_features': 0.2, 'min_samples_leaf': 50, 'n_estimators': 10},\n",
       "  {'max_features': 0.2, 'min_samples_leaf': 50, 'n_estimators': 50},\n",
       "  {'max_features': 0.2, 'min_samples_leaf': 50, 'n_estimators': 100},\n",
       "  {'max_features': 0.3, 'min_samples_leaf': 1, 'n_estimators': 10},\n",
       "  {'max_features': 0.3, 'min_samples_leaf': 1, 'n_estimators': 50},\n",
       "  {'max_features': 0.3, 'min_samples_leaf': 1, 'n_estimators': 100},\n",
       "  {'max_features': 0.3, 'min_samples_leaf': 5, 'n_estimators': 10},\n",
       "  {'max_features': 0.3, 'min_samples_leaf': 5, 'n_estimators': 50},\n",
       "  {'max_features': 0.3, 'min_samples_leaf': 5, 'n_estimators': 100},\n",
       "  {'max_features': 0.3, 'min_samples_leaf': 10, 'n_estimators': 10},\n",
       "  {'max_features': 0.3, 'min_samples_leaf': 10, 'n_estimators': 50},\n",
       "  {'max_features': 0.3, 'min_samples_leaf': 10, 'n_estimators': 100},\n",
       "  {'max_features': 0.3, 'min_samples_leaf': 25, 'n_estimators': 10},\n",
       "  {'max_features': 0.3, 'min_samples_leaf': 25, 'n_estimators': 50},\n",
       "  {'max_features': 0.3, 'min_samples_leaf': 25, 'n_estimators': 100},\n",
       "  {'max_features': 0.3, 'min_samples_leaf': 50, 'n_estimators': 10},\n",
       "  {'max_features': 0.3, 'min_samples_leaf': 50, 'n_estimators': 50},\n",
       "  {'max_features': 0.3, 'min_samples_leaf': 50, 'n_estimators': 100},\n",
       "  {'max_features': 0.4, 'min_samples_leaf': 1, 'n_estimators': 10},\n",
       "  {'max_features': 0.4, 'min_samples_leaf': 1, 'n_estimators': 50},\n",
       "  {'max_features': 0.4, 'min_samples_leaf': 1, 'n_estimators': 100},\n",
       "  {'max_features': 0.4, 'min_samples_leaf': 5, 'n_estimators': 10},\n",
       "  {'max_features': 0.4, 'min_samples_leaf': 5, 'n_estimators': 50},\n",
       "  {'max_features': 0.4, 'min_samples_leaf': 5, 'n_estimators': 100},\n",
       "  {'max_features': 0.4, 'min_samples_leaf': 10, 'n_estimators': 10},\n",
       "  {'max_features': 0.4, 'min_samples_leaf': 10, 'n_estimators': 50},\n",
       "  {'max_features': 0.4, 'min_samples_leaf': 10, 'n_estimators': 100},\n",
       "  {'max_features': 0.4, 'min_samples_leaf': 25, 'n_estimators': 10},\n",
       "  {'max_features': 0.4, 'min_samples_leaf': 25, 'n_estimators': 50},\n",
       "  {'max_features': 0.4, 'min_samples_leaf': 25, 'n_estimators': 100},\n",
       "  {'max_features': 0.4, 'min_samples_leaf': 50, 'n_estimators': 10},\n",
       "  {'max_features': 0.4, 'min_samples_leaf': 50, 'n_estimators': 50},\n",
       "  {'max_features': 0.4, 'min_samples_leaf': 50, 'n_estimators': 100},\n",
       "  {'max_features': 0.5, 'min_samples_leaf': 1, 'n_estimators': 10},\n",
       "  {'max_features': 0.5, 'min_samples_leaf': 1, 'n_estimators': 50},\n",
       "  {'max_features': 0.5, 'min_samples_leaf': 1, 'n_estimators': 100},\n",
       "  {'max_features': 0.5, 'min_samples_leaf': 5, 'n_estimators': 10},\n",
       "  {'max_features': 0.5, 'min_samples_leaf': 5, 'n_estimators': 50},\n",
       "  {'max_features': 0.5, 'min_samples_leaf': 5, 'n_estimators': 100},\n",
       "  {'max_features': 0.5, 'min_samples_leaf': 10, 'n_estimators': 10},\n",
       "  {'max_features': 0.5, 'min_samples_leaf': 10, 'n_estimators': 50},\n",
       "  {'max_features': 0.5, 'min_samples_leaf': 10, 'n_estimators': 100},\n",
       "  {'max_features': 0.5, 'min_samples_leaf': 25, 'n_estimators': 10},\n",
       "  {'max_features': 0.5, 'min_samples_leaf': 25, 'n_estimators': 50},\n",
       "  {'max_features': 0.5, 'min_samples_leaf': 25, 'n_estimators': 100},\n",
       "  {'max_features': 0.5, 'min_samples_leaf': 50, 'n_estimators': 10},\n",
       "  {'max_features': 0.5, 'min_samples_leaf': 50, 'n_estimators': 50},\n",
       "  {'max_features': 0.5, 'min_samples_leaf': 50, 'n_estimators': 100},\n",
       "  {'max_features': 0.6, 'min_samples_leaf': 1, 'n_estimators': 10},\n",
       "  {'max_features': 0.6, 'min_samples_leaf': 1, 'n_estimators': 50},\n",
       "  {'max_features': 0.6, 'min_samples_leaf': 1, 'n_estimators': 100},\n",
       "  {'max_features': 0.6, 'min_samples_leaf': 5, 'n_estimators': 10},\n",
       "  {'max_features': 0.6, 'min_samples_leaf': 5, 'n_estimators': 50},\n",
       "  {'max_features': 0.6, 'min_samples_leaf': 5, 'n_estimators': 100},\n",
       "  {'max_features': 0.6, 'min_samples_leaf': 10, 'n_estimators': 10},\n",
       "  {'max_features': 0.6, 'min_samples_leaf': 10, 'n_estimators': 50},\n",
       "  {'max_features': 0.6, 'min_samples_leaf': 10, 'n_estimators': 100},\n",
       "  {'max_features': 0.6, 'min_samples_leaf': 25, 'n_estimators': 10},\n",
       "  {'max_features': 0.6, 'min_samples_leaf': 25, 'n_estimators': 50},\n",
       "  {'max_features': 0.6, 'min_samples_leaf': 25, 'n_estimators': 100},\n",
       "  {'max_features': 0.6, 'min_samples_leaf': 50, 'n_estimators': 10},\n",
       "  {'max_features': 0.6, 'min_samples_leaf': 50, 'n_estimators': 50},\n",
       "  {'max_features': 0.6, 'min_samples_leaf': 50, 'n_estimators': 100},\n",
       "  {'max_features': 0.7, 'min_samples_leaf': 1, 'n_estimators': 10},\n",
       "  {'max_features': 0.7, 'min_samples_leaf': 1, 'n_estimators': 50},\n",
       "  {'max_features': 0.7, 'min_samples_leaf': 1, 'n_estimators': 100},\n",
       "  {'max_features': 0.7, 'min_samples_leaf': 5, 'n_estimators': 10},\n",
       "  {'max_features': 0.7, 'min_samples_leaf': 5, 'n_estimators': 50},\n",
       "  {'max_features': 0.7, 'min_samples_leaf': 5, 'n_estimators': 100},\n",
       "  {'max_features': 0.7, 'min_samples_leaf': 10, 'n_estimators': 10},\n",
       "  {'max_features': 0.7, 'min_samples_leaf': 10, 'n_estimators': 50},\n",
       "  {'max_features': 0.7, 'min_samples_leaf': 10, 'n_estimators': 100},\n",
       "  {'max_features': 0.7, 'min_samples_leaf': 25, 'n_estimators': 10},\n",
       "  {'max_features': 0.7, 'min_samples_leaf': 25, 'n_estimators': 50},\n",
       "  {'max_features': 0.7, 'min_samples_leaf': 25, 'n_estimators': 100},\n",
       "  {'max_features': 0.7, 'min_samples_leaf': 50, 'n_estimators': 10},\n",
       "  {'max_features': 0.7, 'min_samples_leaf': 50, 'n_estimators': 50},\n",
       "  {'max_features': 0.7, 'min_samples_leaf': 50, 'n_estimators': 100},\n",
       "  {'max_features': 0.8, 'min_samples_leaf': 1, 'n_estimators': 10},\n",
       "  {'max_features': 0.8, 'min_samples_leaf': 1, 'n_estimators': 50},\n",
       "  {'max_features': 0.8, 'min_samples_leaf': 1, 'n_estimators': 100},\n",
       "  {'max_features': 0.8, 'min_samples_leaf': 5, 'n_estimators': 10},\n",
       "  {'max_features': 0.8, 'min_samples_leaf': 5, 'n_estimators': 50},\n",
       "  {'max_features': 0.8, 'min_samples_leaf': 5, 'n_estimators': 100},\n",
       "  {'max_features': 0.8, 'min_samples_leaf': 10, 'n_estimators': 10},\n",
       "  {'max_features': 0.8, 'min_samples_leaf': 10, 'n_estimators': 50},\n",
       "  {'max_features': 0.8, 'min_samples_leaf': 10, 'n_estimators': 100},\n",
       "  {'max_features': 0.8, 'min_samples_leaf': 25, 'n_estimators': 10},\n",
       "  {'max_features': 0.8, 'min_samples_leaf': 25, 'n_estimators': 50},\n",
       "  {'max_features': 0.8, 'min_samples_leaf': 25, 'n_estimators': 100},\n",
       "  {'max_features': 0.8, 'min_samples_leaf': 50, 'n_estimators': 10},\n",
       "  {'max_features': 0.8, 'min_samples_leaf': 50, 'n_estimators': 50},\n",
       "  {'max_features': 0.8, 'min_samples_leaf': 50, 'n_estimators': 100}],\n",
       " 'split0_test_score': array([0.66469171, 0.7258262 , 0.69054199, 0.55208773, 0.67276685,\n",
       "        0.66986352, 0.63075555, 0.65040729, 0.61214888, 0.50250637,\n",
       "        0.49784278, 0.54511825, 0.37755301, 0.38162104, 0.37190252,\n",
       "        0.71947126, 0.76299967, 0.74586838, 0.75741681, 0.69967444,\n",
       "        0.71388807, 0.71765234, 0.71236378, 0.68749469, 0.60332967,\n",
       "        0.66516379, 0.59227745, 0.53291665, 0.55970392, 0.53642354,\n",
       "        0.74806153, 0.75357244, 0.76588967, 0.75987896, 0.76095958,\n",
       "        0.75027925, 0.71149734, 0.73068744, 0.74802531, 0.62473427,\n",
       "        0.69203486, 0.70632931, 0.70291856, 0.62622485, 0.63789337,\n",
       "        0.75057502, 0.75538592, 0.76393769, 0.76020036, 0.75275352,\n",
       "        0.75390008, 0.74576531, 0.75058712, 0.76587225, 0.67603836,\n",
       "        0.71334169, 0.7156117 , 0.72902675, 0.61949182, 0.58677723,\n",
       "        0.70593298, 0.77211876, 0.76917873, 0.74958939, 0.76884534,\n",
       "        0.75952258, 0.67911221, 0.74759697, 0.75188784, 0.66926534,\n",
       "        0.70071654, 0.71717157, 0.51604075, 0.51618346, 0.61136552,\n",
       "        0.76307671, 0.75861027, 0.76600689, 0.77300504, 0.75381791,\n",
       "        0.7585582 , 0.74841295, 0.7688635 , 0.76243653, 0.75508967,\n",
       "        0.73972112, 0.71897545, 0.54526249, 0.59225151, 0.62296313,\n",
       "        0.75637016, 0.74775036, 0.76213602, 0.73882257, 0.76651717,\n",
       "        0.76156032, 0.74914857, 0.76010886, 0.75832518, 0.71562394,\n",
       "        0.72547169, 0.71524763, 0.58062936, 0.5501526 , 0.56473356]),\n",
       " 'split1_test_score': array([0.71468194, 0.79101988, 0.75853309, 0.76228811, 0.75167516,\n",
       "        0.74085074, 0.69754649, 0.71460504, 0.68426661, 0.67046617,\n",
       "        0.66864172, 0.61129777, 0.45691627, 0.48926567, 0.51404335,\n",
       "        0.8354511 , 0.85032922, 0.83791052, 0.80901359, 0.82498142,\n",
       "        0.83698952, 0.72611621, 0.7779197 , 0.76750095, 0.66051961,\n",
       "        0.67470496, 0.67132107, 0.55767696, 0.50906588, 0.55142849,\n",
       "        0.80892161, 0.87277154, 0.85520451, 0.84473762, 0.857374  ,\n",
       "        0.8503137 , 0.79460364, 0.84176424, 0.84762733, 0.74928161,\n",
       "        0.78278565, 0.7719476 , 0.66441315, 0.63210366, 0.65888684,\n",
       "        0.82713114, 0.86314893, 0.86056193, 0.83257121, 0.85694785,\n",
       "        0.85461607, 0.86775545, 0.85098687, 0.85440862, 0.7564211 ,\n",
       "        0.78641166, 0.79130418, 0.63508872, 0.67878687, 0.67999463,\n",
       "        0.86956302, 0.86547561, 0.86619493, 0.84712039, 0.86833003,\n",
       "        0.86946451, 0.86493109, 0.84493526, 0.86751006, 0.79465453,\n",
       "        0.78702268, 0.79311098, 0.68623276, 0.68882276, 0.67873215,\n",
       "        0.84220591, 0.86285256, 0.8672785 , 0.84134812, 0.86919046,\n",
       "        0.86541058, 0.88048049, 0.86584746, 0.86293784, 0.79899619,\n",
       "        0.79333353, 0.80134332, 0.69566822, 0.70805771, 0.69948634,\n",
       "        0.86101981, 0.85485628, 0.86552427, 0.85893664, 0.86481042,\n",
       "        0.87196172, 0.86262551, 0.87057381, 0.8766442 , 0.80450771,\n",
       "        0.81207293, 0.79956434, 0.65653923, 0.70031192, 0.7041168 ]),\n",
       " 'split2_test_score': array([ 0.54964222,  0.70327535,  0.66747249,  0.59742866,  0.50691772,\n",
       "         0.49823325,  0.469     ,  0.4551675 ,  0.40273661,  0.01662846,\n",
       "         0.26946217,  0.20862888, -0.05398563, -0.00839911, -0.0622395 ,\n",
       "         0.6880131 ,  0.67500723,  0.7629998 ,  0.64800925,  0.64685598,\n",
       "         0.66049382,  0.38563974,  0.51108391,  0.54486746,  0.48108215,\n",
       "         0.39124348,  0.33037144,  0.13920834,  0.0682255 ,  0.08526082,\n",
       "         0.56748803,  0.78335728,  0.75036591,  0.78643853,  0.6865434 ,\n",
       "         0.74190713,  0.52527167,  0.67822511,  0.66408131,  0.44233451,\n",
       "         0.43347196,  0.47265279,  0.1425405 ,  0.16796235,  0.17019016,\n",
       "         0.74983204,  0.80157342,  0.77098958,  0.68622428,  0.72878265,\n",
       "         0.7370842 ,  0.69280928,  0.68515325,  0.66801861,  0.49432789,\n",
       "         0.49254003,  0.51461551,  0.22102581,  0.14345221,  0.19063649,\n",
       "         0.73259193,  0.73508006,  0.76117791,  0.73728506,  0.7617729 ,\n",
       "         0.75295559,  0.58485661,  0.66519963,  0.67109177,  0.51444366,\n",
       "         0.46368817,  0.50217649,  0.21844401,  0.1706444 ,  0.16097927,\n",
       "         0.80016307,  0.77502358,  0.74445545,  0.57385761,  0.66550698,\n",
       "         0.70626241,  0.69765104,  0.65489399,  0.64819637,  0.53306915,\n",
       "         0.54386219,  0.53293448,  0.14256497,  0.19777049,  0.17868995,\n",
       "         0.73731221,  0.7301561 ,  0.74614909,  0.67860716,  0.69901577,\n",
       "         0.70827158,  0.70810912,  0.69207323,  0.65871168,  0.52737207,\n",
       "         0.53848951,  0.54447242,  0.21307538,  0.2068038 ,  0.16786124]),\n",
       " 'split3_test_score': array([0.5378443 , 0.48712619, 0.44972416, 0.38944477, 0.38138554,\n",
       "        0.38076815, 0.38720612, 0.31689184, 0.35522464, 0.30299469,\n",
       "        0.28784571, 0.26074053, 0.26870343, 0.2033159 , 0.16836641,\n",
       "        0.48232919, 0.51497283, 0.4828617 , 0.50624189, 0.47234603,\n",
       "        0.41482725, 0.40280336, 0.38062516, 0.39038693, 0.35984781,\n",
       "        0.356703  , 0.28688698, 0.06417712, 0.21958043, 0.23098733,\n",
       "        0.4314718 , 0.53832596, 0.53543566, 0.47633261, 0.45207946,\n",
       "        0.47761833, 0.48690735, 0.46220026, 0.4520264 , 0.36788536,\n",
       "        0.40820795, 0.39767583, 0.29111504, 0.26799378, 0.28249522,\n",
       "        0.47586192, 0.54483561, 0.52399347, 0.47058124, 0.50563355,\n",
       "        0.48423264, 0.44710497, 0.45616203, 0.45004431, 0.38377362,\n",
       "        0.42143469, 0.39090185, 0.25019398, 0.33500101, 0.31202336,\n",
       "        0.47969348, 0.49810944, 0.53781994, 0.47209683, 0.45454431,\n",
       "        0.49372299, 0.4615851 , 0.46606605, 0.46306343, 0.42526864,\n",
       "        0.4112222 , 0.38405683, 0.31675376, 0.30532358, 0.33223905,\n",
       "        0.49321231, 0.50725234, 0.51535906, 0.47033366, 0.4719627 ,\n",
       "        0.48745512, 0.37503723, 0.43537776, 0.46007708, 0.40214193,\n",
       "        0.41575131, 0.41154234, 0.31438911, 0.35278843, 0.34877693,\n",
       "        0.48322878, 0.50289159, 0.48387742, 0.4660534 , 0.44234609,\n",
       "        0.47621891, 0.41037632, 0.44198388, 0.44793548, 0.38762662,\n",
       "        0.42677194, 0.41594358, 0.38797562, 0.33926198, 0.35397841]),\n",
       " 'split4_test_score': array([-0.59958822,  0.01638527,  0.10942432,  0.26219138,  0.14591706,\n",
       "         0.07362711,  0.28607078,  0.01868555,  0.28197754, -0.17591221,\n",
       "         0.01935629,  0.00622757, -0.11207636, -0.30310526, -0.35112948,\n",
       "         0.11092231,  0.12271241,  0.17584339,  0.20253243,  0.30284234,\n",
       "         0.30517937,  0.09461523,  0.27343113,  0.25283407, -0.0366791 ,\n",
       "         0.24583535,  0.20740351, -0.13942444, -0.12427278, -0.16065312,\n",
       "         0.04539364,  0.15210937,  0.3239508 ,  0.50016773,  0.35141257,\n",
       "         0.38160728,  0.19421157,  0.34197256,  0.3129    ,  0.01342744,\n",
       "         0.20583511,  0.14937581,  0.05912971, -0.02620745, -0.03461473,\n",
       "         0.42843976,  0.36585608,  0.37454026,  0.26047467,  0.44804645,\n",
       "         0.37761167,  0.26312724,  0.38310024,  0.38844355,  0.2208278 ,\n",
       "         0.20512392,  0.17280421, -0.16536919, -0.11680998, -0.03788121,\n",
       "         0.40095412,  0.39310014,  0.35538798,  0.30968762,  0.32307149,\n",
       "         0.40914866,  0.32498045,  0.29623359,  0.35828357,  0.18727698,\n",
       "         0.12055195,  0.20590743, -0.28203088, -0.04501557, -0.08367567,\n",
       "         0.24130453,  0.37670725,  0.36055295,  0.1654146 ,  0.35242196,\n",
       "         0.37734089,  0.30444276,  0.35562311,  0.35393199, -0.04576586,\n",
       "         0.18027357,  0.16137873, -0.31770788, -0.16090503, -0.19564015,\n",
       "         0.45109469,  0.30241018,  0.36720618,  0.32310243,  0.30785884,\n",
       "         0.40004346,  0.31987787,  0.35088801,  0.38273781,  0.1066867 ,\n",
       "         0.16746369,  0.0818526 , -0.26871611, -0.1386843 , -0.19728588]),\n",
       " 'mean_test_score': array([0.37402996, 0.54508448, 0.53544633, 0.512766  , 0.49209024,\n",
       "        0.47305827, 0.49438583, 0.43158476, 0.46755718, 0.26380936,\n",
       "        0.34892462, 0.32683485, 0.1877979 , 0.15299238, 0.12867031,\n",
       "        0.56753825, 0.58555565, 0.60138287, 0.58498425, 0.58955809,\n",
       "        0.58652781, 0.46586397, 0.53144299, 0.52893081, 0.41399495,\n",
       "        0.46712228, 0.4179972 , 0.23150778, 0.24707965, 0.24925806,\n",
       "        0.52071751, 0.62029124, 0.64640591, 0.67368178, 0.62194907,\n",
       "        0.6405624 , 0.5428323 , 0.61120652, 0.60521486, 0.43989865,\n",
       "        0.5048378 , 0.50000483, 0.37267733, 0.33419372, 0.34355302,\n",
       "        0.64657392, 0.66633633, 0.65901236, 0.60232298, 0.65861921,\n",
       "        0.64171109, 0.60359398, 0.62544571, 0.62563517, 0.50661325,\n",
       "        0.52414504, 0.51743991, 0.33477391, 0.33255258, 0.34678533,\n",
       "        0.63788186, 0.65301266, 0.65817171, 0.62340573, 0.63557671,\n",
       "        0.65716555, 0.58328285, 0.60429008, 0.6226233 , 0.51848041,\n",
       "        0.49704362, 0.52087337, 0.29153265, 0.32756523, 0.3404645 ,\n",
       "        0.62825947, 0.65629181, 0.65095839, 0.56520329, 0.62283937,\n",
       "        0.63924171, 0.60149582, 0.61642302, 0.61780237, 0.48923267,\n",
       "        0.53499375, 0.52561775, 0.27656745, 0.33849511, 0.33143253,\n",
       "        0.65799992, 0.62785033, 0.64521013, 0.6133529 , 0.61640691,\n",
       "        0.6438443 , 0.61030242, 0.62339628, 0.62513461, 0.50877301,\n",
       "        0.53443225, 0.51181894, 0.31442783, 0.33200118, 0.3191671 ]),\n",
       " 'std_test_score': array([0.49083324, 0.28305065, 0.2365504 , 0.17244818, 0.21550083,\n",
       "        0.23620867, 0.15189058, 0.24981447, 0.15433794, 0.30917718,\n",
       "        0.2203609 , 0.22346109, 0.22943259, 0.28343523, 0.30839862,\n",
       "        0.25484088, 0.25630456, 0.244004  , 0.21734338, 0.18251992,\n",
       "        0.19638709, 0.23640692, 0.19140276, 0.18848512, 0.24775348,\n",
       "        0.17281294, 0.18096461, 0.2725828 , 0.25973759, 0.27170301,\n",
       "        0.27225349, 0.25827455, 0.19222285, 0.1538163 , 0.19015796,\n",
       "        0.17872638, 0.20816422, 0.18244211, 0.19563311, 0.2516596 ,\n",
       "        0.2078701 , 0.22387852, 0.26551021, 0.25927422, 0.26944543,\n",
       "        0.16164953, 0.18425378, 0.18061614, 0.20928841, 0.15537865,\n",
       "        0.17964631, 0.21821476, 0.17738432, 0.17931451, 0.19387352,\n",
       "        0.2087223 , 0.22314262, 0.32136466, 0.29659675, 0.26156324,\n",
       "        0.17215565, 0.17744861, 0.18555331, 0.20000704, 0.20882359,\n",
       "        0.17478595, 0.18428057, 0.19797823, 0.18664587, 0.20842442,\n",
       "        0.23480173, 0.2148686 , 0.3288081 , 0.25679504, 0.28281603,\n",
       "        0.22853198, 0.18296783, 0.18508734, 0.24008354, 0.18728411,\n",
       "        0.1796292 , 0.22267004, 0.19369217, 0.18777492, 0.30402234,\n",
       "        0.22302424, 0.22759871, 0.35210229, 0.3066215 , 0.32301667,\n",
       "        0.16147853, 0.19882209, 0.18735044, 0.19289483, 0.208017  ,\n",
       "        0.17743062, 0.20812986, 0.19569399, 0.18553425, 0.24769267,\n",
       "        0.22790376, 0.25262142, 0.32962638, 0.28988066, 0.31588834]),\n",
       " 'rank_test_score': array([ 81,  50,  52,  63,  71,  73,  70,  78,  74,  99,  83,  94, 103,\n",
       "        104, 105,  48,  45,  42,  46,  43,  44,  76,  55,  56,  80,  75,\n",
       "         79, 102, 101, 100,  60,  30,  12,   1,  29,  16,  51,  35,  37,\n",
       "         77,  67,  68,  82,  89,  85,  11,   2,   3,  40,   4,  15,  39,\n",
       "         23,  22,  66,  58,  62,  88,  90,  84,  18,   9,   5,  25,  19,\n",
       "          7,  47,  38,  28,  61,  69,  59,  97,  93,  86,  20,   8,  10,\n",
       "         49,  27,  17,  41,  32,  31,  72,  53,  57,  98,  87,  92,   6,\n",
       "         21,  13,  34,  33,  14,  36,  26,  24,  65,  54,  64,  96,  91,\n",
       "         95]),\n",
       " 'split0_train_score': array([0.97506484, 0.97880778, 0.9799909 , 0.87496134, 0.8812891 ,\n",
       "        0.88301715, 0.79801506, 0.81910154, 0.80116823, 0.68666422,\n",
       "        0.67806323, 0.68596052, 0.53831276, 0.55069597, 0.55213005,\n",
       "        0.96461732, 0.98141484, 0.9833503 , 0.90246004, 0.90672215,\n",
       "        0.89380487, 0.82820479, 0.83101963, 0.84117873, 0.76156116,\n",
       "        0.75544482, 0.73711812, 0.60250427, 0.63501495, 0.62497373,\n",
       "        0.97458372, 0.98426351, 0.98445853, 0.91180154, 0.92402176,\n",
       "        0.92152123, 0.8654136 , 0.86692521, 0.87462819, 0.75719891,\n",
       "        0.78814917, 0.7813497 , 0.68331536, 0.66369257, 0.67121201,\n",
       "        0.97772442, 0.98163074, 0.98408337, 0.91558743, 0.91808105,\n",
       "        0.91995644, 0.88283765, 0.87628768, 0.87916077, 0.78134591,\n",
       "        0.78951039, 0.78854093, 0.64676389, 0.6657743 , 0.66782218,\n",
       "        0.97850134, 0.98446836, 0.98543414, 0.91855066, 0.91923396,\n",
       "        0.92342438, 0.87226817, 0.87760864, 0.88009183, 0.78085505,\n",
       "        0.79201043, 0.80122059, 0.67017787, 0.65754661, 0.67115765,\n",
       "        0.97328366, 0.98291983, 0.9837634 , 0.92249114, 0.92392382,\n",
       "        0.92835583, 0.87697575, 0.88247058, 0.87961058, 0.79867115,\n",
       "        0.79505651, 0.80035522, 0.66722303, 0.68115287, 0.68583353,\n",
       "        0.97956706, 0.98587031, 0.98541539, 0.92056728, 0.92110432,\n",
       "        0.92740618, 0.8787436 , 0.87972612, 0.87900059, 0.79229029,\n",
       "        0.80178053, 0.79885071, 0.67343987, 0.67983172, 0.68890778]),\n",
       " 'split1_train_score': array([0.96766252, 0.97499423, 0.97824074, 0.87185109, 0.85146495,\n",
       "        0.8635843 , 0.78466571, 0.78350154, 0.79044809, 0.67867379,\n",
       "        0.68890055, 0.66652534, 0.51557663, 0.52497568, 0.55658073,\n",
       "        0.97981056, 0.98041985, 0.98214362, 0.88649703, 0.88512572,\n",
       "        0.8890652 , 0.80548135, 0.82615756, 0.83305592, 0.70693635,\n",
       "        0.70545318, 0.71203578, 0.58668261, 0.56870321, 0.58939782,\n",
       "        0.96938347, 0.98261057, 0.98259478, 0.90960489, 0.90416341,\n",
       "        0.90636997, 0.84024297, 0.85713846, 0.85339248, 0.73854684,\n",
       "        0.76453134, 0.76012861, 0.66083219, 0.62404226, 0.63941565,\n",
       "        0.97226833, 0.9788373 , 0.98317706, 0.91274164, 0.91325926,\n",
       "        0.91214619, 0.84366592, 0.85715361, 0.86007165, 0.75674881,\n",
       "        0.77573065, 0.76985676, 0.62802719, 0.65393807, 0.64966022,\n",
       "        0.9764661 , 0.98322215, 0.98068132, 0.89583403, 0.91045781,\n",
       "        0.91672263, 0.8458429 , 0.85838188, 0.85937332, 0.75848381,\n",
       "        0.77003555, 0.77479291, 0.64929555, 0.65621038, 0.64375179,\n",
       "        0.97346212, 0.97857138, 0.98204592, 0.90767628, 0.91125255,\n",
       "        0.91571332, 0.85881093, 0.86136468, 0.85999097, 0.76923733,\n",
       "        0.77238946, 0.77042984, 0.66603217, 0.67411192, 0.66431053,\n",
       "        0.969565  , 0.98210749, 0.98081501, 0.90036627, 0.91882703,\n",
       "        0.91596777, 0.85468698, 0.86624264, 0.86405845, 0.76219453,\n",
       "        0.77419175, 0.77935152, 0.62922237, 0.67066728, 0.65934494]),\n",
       " 'split2_train_score': array([0.95648835, 0.97068965, 0.97541647, 0.78294586, 0.85660024,\n",
       "        0.83894015, 0.71740725, 0.76560193, 0.74439214, 0.54596339,\n",
       "        0.63435862, 0.60529999, 0.51517728, 0.48482118, 0.48562083,\n",
       "        0.95718613, 0.97603958, 0.97532574, 0.86903359, 0.87333439,\n",
       "        0.86628774, 0.7689865 , 0.7870329 , 0.80247566, 0.68556477,\n",
       "        0.67635217, 0.67109074, 0.51928657, 0.54345895, 0.53088699,\n",
       "        0.96301583, 0.97961802, 0.97978543, 0.89297564, 0.89367921,\n",
       "        0.8939995 , 0.80248278, 0.83301563, 0.81741991, 0.70584622,\n",
       "        0.70842515, 0.71629841, 0.53874054, 0.59306606, 0.58884274,\n",
       "        0.97224539, 0.97989251, 0.98000823, 0.87851452, 0.89857461,\n",
       "        0.90240481, 0.77883814, 0.83258468, 0.82797585, 0.71100427,\n",
       "        0.73120412, 0.73449245, 0.58260923, 0.58285475, 0.59115076,\n",
       "        0.97575501, 0.97860575, 0.97928674, 0.88221508, 0.89786505,\n",
       "        0.89754158, 0.83388286, 0.82921441, 0.84097155, 0.72894076,\n",
       "        0.72760055, 0.73741684, 0.59410589, 0.5959561 , 0.5950787 ,\n",
       "        0.96760355, 0.97869922, 0.97848877, 0.88793931, 0.90361143,\n",
       "        0.90346368, 0.83926212, 0.83791299, 0.83968619, 0.74381215,\n",
       "        0.74603245, 0.74003393, 0.59648395, 0.60062206, 0.60831096,\n",
       "        0.97138596, 0.97995582, 0.98063756, 0.88966498, 0.90403332,\n",
       "        0.90927278, 0.82061212, 0.84583363, 0.84502254, 0.74027036,\n",
       "        0.74336619, 0.74896496, 0.60939439, 0.60399832, 0.60932077]),\n",
       " 'split3_train_score': array([0.9799083 , 0.98448357, 0.98495237, 0.89675007, 0.90547792,\n",
       "        0.91206274, 0.86483564, 0.85041318, 0.86870506, 0.74977813,\n",
       "        0.76740911, 0.76132717, 0.63141005, 0.64821527, 0.62023916,\n",
       "        0.98042825, 0.98554367, 0.98677469, 0.9183883 , 0.93471899,\n",
       "        0.92883776, 0.85529169, 0.88649563, 0.88871273, 0.76109625,\n",
       "        0.81048517, 0.7923127 , 0.60399648, 0.66998762, 0.66767493,\n",
       "        0.97940898, 0.98617254, 0.98785512, 0.93657492, 0.94468218,\n",
       "        0.94643632, 0.91047667, 0.91309883, 0.91597544, 0.81186099,\n",
       "        0.82416922, 0.82979424, 0.72792762, 0.72842754, 0.71663661,\n",
       "        0.98089457, 0.98649146, 0.98748864, 0.94779039, 0.94511267,\n",
       "        0.94804816, 0.9111164 , 0.91534235, 0.91896773, 0.82691059,\n",
       "        0.83612362, 0.84390165, 0.6988717 , 0.75538151, 0.72312154,\n",
       "        0.98018242, 0.98603107, 0.98717029, 0.94322637, 0.94823775,\n",
       "        0.94911855, 0.91588255, 0.92175963, 0.92398734, 0.85194039,\n",
       "        0.84784361, 0.84102332, 0.69679308, 0.74054781, 0.73905607,\n",
       "        0.97761998, 0.98661235, 0.98721706, 0.94029034, 0.95009907,\n",
       "        0.95127888, 0.91560668, 0.92310891, 0.92473712, 0.84984235,\n",
       "        0.83811336, 0.84479667, 0.72886655, 0.74666986, 0.7390964 ,\n",
       "        0.97946764, 0.98675424, 0.98651833, 0.94114914, 0.94711702,\n",
       "        0.94980545, 0.91808227, 0.91962312, 0.92233789, 0.83195293,\n",
       "        0.83903592, 0.8393959 , 0.73739886, 0.73600579, 0.74009352]),\n",
       " 'split4_train_score': array([0.96905121, 0.98232568, 0.98116348, 0.8432603 , 0.87745424,\n",
       "        0.87653605, 0.73587889, 0.78989776, 0.80487547, 0.63805634,\n",
       "        0.63559111, 0.65903475, 0.5964228 , 0.50151494, 0.47731851,\n",
       "        0.97503589, 0.9792601 , 0.98281066, 0.87563364, 0.9002274 ,\n",
       "        0.90317237, 0.81899179, 0.83349482, 0.85268382, 0.64472071,\n",
       "        0.70511257, 0.71757146, 0.59942294, 0.58970108, 0.56292267,\n",
       "        0.97739808, 0.98466965, 0.98261326, 0.91558313, 0.91007531,\n",
       "        0.91768771, 0.86030145, 0.86877378, 0.86934876, 0.75641161,\n",
       "        0.76022949, 0.75575994, 0.66779193, 0.65110621, 0.64897145,\n",
       "        0.97157295, 0.98083238, 0.98356748, 0.90316728, 0.90807604,\n",
       "        0.92003136, 0.85930292, 0.87004399, 0.87167877, 0.76430961,\n",
       "        0.76523301, 0.7673697 , 0.65002153, 0.6590399 , 0.6657641 ,\n",
       "        0.9760182 , 0.98064231, 0.98191826, 0.90872594, 0.92094871,\n",
       "        0.91695967, 0.85451131, 0.8713398 , 0.87576093, 0.77786053,\n",
       "        0.77014255, 0.78582404, 0.65097688, 0.66812532, 0.66071286,\n",
       "        0.98240015, 0.98342033, 0.98341289, 0.90755352, 0.92246023,\n",
       "        0.91997555, 0.86304207, 0.87864558, 0.87647744, 0.77555835,\n",
       "        0.78495349, 0.78493458, 0.65699546, 0.68117668, 0.6718356 ,\n",
       "        0.97417372, 0.9801994 , 0.98366751, 0.92181304, 0.91713414,\n",
       "        0.92090968, 0.86901387, 0.86968276, 0.87608725, 0.78898063,\n",
       "        0.79061435, 0.79109522, 0.65903059, 0.67002592, 0.67241545]),\n",
       " 'mean_train_score': array([0.96963504, 0.97826018, 0.97995279, 0.85395373, 0.87445729,\n",
       "        0.87482808, 0.78016051, 0.80170319, 0.8019178 , 0.65982718,\n",
       "        0.68086452, 0.67562956, 0.5593799 , 0.54204461, 0.53837786,\n",
       "        0.97141563, 0.98053561, 0.982081  , 0.89040252, 0.90002573,\n",
       "        0.89623359, 0.81539122, 0.83284011, 0.84362137, 0.71197585,\n",
       "        0.73056958, 0.72602576, 0.58237857, 0.60137316, 0.59517123,\n",
       "        0.97275802, 0.98346686, 0.98346142, 0.91330802, 0.91532437,\n",
       "        0.91720295, 0.85578349, 0.86779038, 0.86615296, 0.75397291,\n",
       "        0.76910087, 0.76866618, 0.65572153, 0.65206693, 0.65301569,\n",
       "        0.97494113, 0.98153688, 0.98366496, 0.91156025, 0.91662073,\n",
       "        0.92051739, 0.85515221, 0.87028246, 0.87157095, 0.76806384,\n",
       "        0.77956036, 0.7808323 , 0.64125871, 0.66339771, 0.65950376,\n",
       "        0.97738461, 0.98259393, 0.98289815, 0.90971042, 0.91934866,\n",
       "        0.92075336, 0.86447756, 0.87166087, 0.87603699, 0.77961611,\n",
       "        0.78152654, 0.78805554, 0.65226986, 0.66367724, 0.66195141,\n",
       "        0.97487389, 0.98204462, 0.98298561, 0.91319012, 0.92226942,\n",
       "        0.92375745, 0.87073951, 0.87670055, 0.87610046, 0.78742427,\n",
       "        0.78730905, 0.78811005, 0.66312023, 0.67674668, 0.6738774 ,\n",
       "        0.97483188, 0.98297745, 0.98341076, 0.91471214, 0.92164317,\n",
       "        0.92467237, 0.86822777, 0.87622166, 0.87730135, 0.78313775,\n",
       "        0.78979775, 0.79153166, 0.66169722, 0.67210581, 0.67401649]),\n",
       " 'std_train_score': array([0.0079005 , 0.00497068, 0.0031614 , 0.0393691 , 0.01931557,\n",
       "        0.02396149, 0.05178377, 0.02983064, 0.03977588, 0.06723917,\n",
       "        0.04852808, 0.05050808, 0.04664106, 0.05754229, 0.05240856,\n",
       "        0.009094  , 0.00308896, 0.00373662, 0.01799217, 0.0208947 ,\n",
       "        0.02032347, 0.02835773, 0.03170367, 0.02802114, 0.0449838 ,\n",
       "        0.04737869, 0.03950202, 0.03213103, 0.04560117, 0.04764607,\n",
       "        0.00592278, 0.00223378, 0.0026564 , 0.01397078, 0.01765309,\n",
       "        0.01748843, 0.03517661, 0.02598968, 0.0319439 , 0.03441374,\n",
       "        0.03788531, 0.03709274, 0.06297857, 0.04524048, 0.04170902,\n",
       "        0.00371337, 0.00264744, 0.0023839 , 0.022328  , 0.01564543,\n",
       "        0.01520945, 0.04443304, 0.02705551, 0.02945111, 0.03751605,\n",
       "        0.03422476, 0.03601736, 0.03752649, 0.0548859 , 0.0422484 ,\n",
       "        0.00169948, 0.0026622 , 0.00295294, 0.0207412 , 0.01659967,\n",
       "        0.01662013, 0.02858594, 0.03007789, 0.02765146, 0.04062015,\n",
       "        0.0391855 , 0.03383507, 0.03375375, 0.04606161, 0.04655019,\n",
       "        0.00493083, 0.00305869, 0.00282125, 0.01743965, 0.01579085,\n",
       "        0.01593375, 0.02547281, 0.02803739, 0.02815494, 0.03576616,\n",
       "        0.03024236, 0.03463323, 0.0420138 , 0.04632535, 0.04193118,\n",
       "        0.0040978 , 0.00283681, 0.00237361, 0.01798213, 0.01405401,\n",
       "        0.01390123, 0.03177192, 0.0243382 , 0.02549489, 0.03090975,\n",
       "        0.0315217 , 0.02934288, 0.04396804, 0.04192355, 0.04240584])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this returns a dictionary, with values generated for each version of the model you tested\n",
    "Grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.837242</td>\n",
       "      <td>1.532662</td>\n",
       "      <td>0.137253</td>\n",
       "      <td>0.047355</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.664692</td>\n",
       "      <td>0.714682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374030</td>\n",
       "      <td>0.490833</td>\n",
       "      <td>81</td>\n",
       "      <td>0.975065</td>\n",
       "      <td>0.967663</td>\n",
       "      <td>0.956488</td>\n",
       "      <td>0.979908</td>\n",
       "      <td>0.969051</td>\n",
       "      <td>0.969635</td>\n",
       "      <td>0.007901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.210489</td>\n",
       "      <td>0.010772</td>\n",
       "      <td>0.124109</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.725826</td>\n",
       "      <td>0.791020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545084</td>\n",
       "      <td>0.283051</td>\n",
       "      <td>50</td>\n",
       "      <td>0.978808</td>\n",
       "      <td>0.974994</td>\n",
       "      <td>0.970690</td>\n",
       "      <td>0.984484</td>\n",
       "      <td>0.982326</td>\n",
       "      <td>0.978260</td>\n",
       "      <td>0.004971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.229695</td>\n",
       "      <td>0.009903</td>\n",
       "      <td>0.118321</td>\n",
       "      <td>0.006714</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.690542</td>\n",
       "      <td>0.758533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535446</td>\n",
       "      <td>0.236550</td>\n",
       "      <td>52</td>\n",
       "      <td>0.979991</td>\n",
       "      <td>0.978241</td>\n",
       "      <td>0.975416</td>\n",
       "      <td>0.984952</td>\n",
       "      <td>0.981163</td>\n",
       "      <td>0.979953</td>\n",
       "      <td>0.003161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.064809</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>0.123606</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.552088</td>\n",
       "      <td>0.762288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512766</td>\n",
       "      <td>0.172448</td>\n",
       "      <td>63</td>\n",
       "      <td>0.874961</td>\n",
       "      <td>0.871851</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.896750</td>\n",
       "      <td>0.843260</td>\n",
       "      <td>0.853954</td>\n",
       "      <td>0.039369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.163775</td>\n",
       "      <td>0.027925</td>\n",
       "      <td>0.120218</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.672767</td>\n",
       "      <td>0.751675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492090</td>\n",
       "      <td>0.215501</td>\n",
       "      <td>71</td>\n",
       "      <td>0.881289</td>\n",
       "      <td>0.851465</td>\n",
       "      <td>0.856600</td>\n",
       "      <td>0.905478</td>\n",
       "      <td>0.877454</td>\n",
       "      <td>0.874457</td>\n",
       "      <td>0.019316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.258020</td>\n",
       "      <td>0.040480</td>\n",
       "      <td>0.115124</td>\n",
       "      <td>0.002950</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.669864</td>\n",
       "      <td>0.740851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473058</td>\n",
       "      <td>0.236209</td>\n",
       "      <td>73</td>\n",
       "      <td>0.883017</td>\n",
       "      <td>0.863584</td>\n",
       "      <td>0.838940</td>\n",
       "      <td>0.912063</td>\n",
       "      <td>0.876536</td>\n",
       "      <td>0.874828</td>\n",
       "      <td>0.023961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.066811</td>\n",
       "      <td>0.007537</td>\n",
       "      <td>0.124494</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 10, ...</td>\n",
       "      <td>0.630756</td>\n",
       "      <td>0.697546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494386</td>\n",
       "      <td>0.151891</td>\n",
       "      <td>70</td>\n",
       "      <td>0.798015</td>\n",
       "      <td>0.784666</td>\n",
       "      <td>0.717407</td>\n",
       "      <td>0.864836</td>\n",
       "      <td>0.735879</td>\n",
       "      <td>0.780161</td>\n",
       "      <td>0.051784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.180930</td>\n",
       "      <td>0.033875</td>\n",
       "      <td>0.125031</td>\n",
       "      <td>0.007291</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 10, ...</td>\n",
       "      <td>0.650407</td>\n",
       "      <td>0.714605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.431585</td>\n",
       "      <td>0.249814</td>\n",
       "      <td>78</td>\n",
       "      <td>0.819102</td>\n",
       "      <td>0.783502</td>\n",
       "      <td>0.765602</td>\n",
       "      <td>0.850413</td>\n",
       "      <td>0.789898</td>\n",
       "      <td>0.801703</td>\n",
       "      <td>0.029831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.203821</td>\n",
       "      <td>0.014191</td>\n",
       "      <td>0.118143</td>\n",
       "      <td>0.005446</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 10, ...</td>\n",
       "      <td>0.612149</td>\n",
       "      <td>0.684267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467557</td>\n",
       "      <td>0.154338</td>\n",
       "      <td>74</td>\n",
       "      <td>0.801168</td>\n",
       "      <td>0.790448</td>\n",
       "      <td>0.744392</td>\n",
       "      <td>0.868705</td>\n",
       "      <td>0.804875</td>\n",
       "      <td>0.801918</td>\n",
       "      <td>0.039776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.063172</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>0.115274</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 25, ...</td>\n",
       "      <td>0.502506</td>\n",
       "      <td>0.670466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263809</td>\n",
       "      <td>0.309177</td>\n",
       "      <td>99</td>\n",
       "      <td>0.686664</td>\n",
       "      <td>0.678674</td>\n",
       "      <td>0.545963</td>\n",
       "      <td>0.749778</td>\n",
       "      <td>0.638056</td>\n",
       "      <td>0.659827</td>\n",
       "      <td>0.067239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.138356</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>0.118105</td>\n",
       "      <td>0.010832</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 25, ...</td>\n",
       "      <td>0.497843</td>\n",
       "      <td>0.668642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348925</td>\n",
       "      <td>0.220361</td>\n",
       "      <td>83</td>\n",
       "      <td>0.678063</td>\n",
       "      <td>0.688901</td>\n",
       "      <td>0.634359</td>\n",
       "      <td>0.767409</td>\n",
       "      <td>0.635591</td>\n",
       "      <td>0.680865</td>\n",
       "      <td>0.048528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.186424</td>\n",
       "      <td>0.030565</td>\n",
       "      <td>0.113383</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 25, ...</td>\n",
       "      <td>0.545118</td>\n",
       "      <td>0.611298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326835</td>\n",
       "      <td>0.223461</td>\n",
       "      <td>94</td>\n",
       "      <td>0.685961</td>\n",
       "      <td>0.666525</td>\n",
       "      <td>0.605300</td>\n",
       "      <td>0.761327</td>\n",
       "      <td>0.659035</td>\n",
       "      <td>0.675630</td>\n",
       "      <td>0.050508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.065988</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.120357</td>\n",
       "      <td>0.003890</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.377553</td>\n",
       "      <td>0.456916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187798</td>\n",
       "      <td>0.229433</td>\n",
       "      <td>103</td>\n",
       "      <td>0.538313</td>\n",
       "      <td>0.515577</td>\n",
       "      <td>0.515177</td>\n",
       "      <td>0.631410</td>\n",
       "      <td>0.596423</td>\n",
       "      <td>0.559380</td>\n",
       "      <td>0.046641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.151941</td>\n",
       "      <td>0.004791</td>\n",
       "      <td>0.125338</td>\n",
       "      <td>0.009015</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.381621</td>\n",
       "      <td>0.489266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152992</td>\n",
       "      <td>0.283435</td>\n",
       "      <td>104</td>\n",
       "      <td>0.550696</td>\n",
       "      <td>0.524976</td>\n",
       "      <td>0.484821</td>\n",
       "      <td>0.648215</td>\n",
       "      <td>0.501515</td>\n",
       "      <td>0.542045</td>\n",
       "      <td>0.057542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.195693</td>\n",
       "      <td>0.014112</td>\n",
       "      <td>0.120310</td>\n",
       "      <td>0.006972</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.371903</td>\n",
       "      <td>0.514043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128670</td>\n",
       "      <td>0.308399</td>\n",
       "      <td>105</td>\n",
       "      <td>0.552130</td>\n",
       "      <td>0.556581</td>\n",
       "      <td>0.485621</td>\n",
       "      <td>0.620239</td>\n",
       "      <td>0.477319</td>\n",
       "      <td>0.538378</td>\n",
       "      <td>0.052409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.052620</td>\n",
       "      <td>0.005979</td>\n",
       "      <td>0.129201</td>\n",
       "      <td>0.008312</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.3, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.719471</td>\n",
       "      <td>0.835451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567538</td>\n",
       "      <td>0.254841</td>\n",
       "      <td>48</td>\n",
       "      <td>0.964617</td>\n",
       "      <td>0.979811</td>\n",
       "      <td>0.957186</td>\n",
       "      <td>0.980428</td>\n",
       "      <td>0.975036</td>\n",
       "      <td>0.971416</td>\n",
       "      <td>0.009094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.181846</td>\n",
       "      <td>0.013012</td>\n",
       "      <td>0.112755</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.3, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.763000</td>\n",
       "      <td>0.850329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585556</td>\n",
       "      <td>0.256305</td>\n",
       "      <td>45</td>\n",
       "      <td>0.981415</td>\n",
       "      <td>0.980420</td>\n",
       "      <td>0.976040</td>\n",
       "      <td>0.985544</td>\n",
       "      <td>0.979260</td>\n",
       "      <td>0.980536</td>\n",
       "      <td>0.003089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.250643</td>\n",
       "      <td>0.025961</td>\n",
       "      <td>0.116473</td>\n",
       "      <td>0.005130</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.3, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.745868</td>\n",
       "      <td>0.837911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.601383</td>\n",
       "      <td>0.244004</td>\n",
       "      <td>42</td>\n",
       "      <td>0.983350</td>\n",
       "      <td>0.982144</td>\n",
       "      <td>0.975326</td>\n",
       "      <td>0.986775</td>\n",
       "      <td>0.982811</td>\n",
       "      <td>0.982081</td>\n",
       "      <td>0.003737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.064086</td>\n",
       "      <td>0.013923</td>\n",
       "      <td>0.114012</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.3, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.757417</td>\n",
       "      <td>0.809014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584984</td>\n",
       "      <td>0.217343</td>\n",
       "      <td>46</td>\n",
       "      <td>0.902460</td>\n",
       "      <td>0.886497</td>\n",
       "      <td>0.869034</td>\n",
       "      <td>0.918388</td>\n",
       "      <td>0.875634</td>\n",
       "      <td>0.890403</td>\n",
       "      <td>0.017992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.189303</td>\n",
       "      <td>0.010706</td>\n",
       "      <td>0.119096</td>\n",
       "      <td>0.007810</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.3, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.699674</td>\n",
       "      <td>0.824981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589558</td>\n",
       "      <td>0.182520</td>\n",
       "      <td>43</td>\n",
       "      <td>0.906722</td>\n",
       "      <td>0.885126</td>\n",
       "      <td>0.873334</td>\n",
       "      <td>0.934719</td>\n",
       "      <td>0.900227</td>\n",
       "      <td>0.900026</td>\n",
       "      <td>0.020895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.240738</td>\n",
       "      <td>0.032439</td>\n",
       "      <td>0.117394</td>\n",
       "      <td>0.009338</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.3, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.713888</td>\n",
       "      <td>0.836990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586528</td>\n",
       "      <td>0.196387</td>\n",
       "      <td>44</td>\n",
       "      <td>0.893805</td>\n",
       "      <td>0.889065</td>\n",
       "      <td>0.866288</td>\n",
       "      <td>0.928838</td>\n",
       "      <td>0.903172</td>\n",
       "      <td>0.896234</td>\n",
       "      <td>0.020323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.068770</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>0.126971</td>\n",
       "      <td>0.006543</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.3, 'min_samples_leaf': 10, ...</td>\n",
       "      <td>0.717652</td>\n",
       "      <td>0.726116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465864</td>\n",
       "      <td>0.236407</td>\n",
       "      <td>76</td>\n",
       "      <td>0.828205</td>\n",
       "      <td>0.805481</td>\n",
       "      <td>0.768986</td>\n",
       "      <td>0.855292</td>\n",
       "      <td>0.818992</td>\n",
       "      <td>0.815391</td>\n",
       "      <td>0.028358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.194144</td>\n",
       "      <td>0.016406</td>\n",
       "      <td>0.124128</td>\n",
       "      <td>0.010155</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.3, 'min_samples_leaf': 10, ...</td>\n",
       "      <td>0.712364</td>\n",
       "      <td>0.777920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531443</td>\n",
       "      <td>0.191403</td>\n",
       "      <td>55</td>\n",
       "      <td>0.831020</td>\n",
       "      <td>0.826158</td>\n",
       "      <td>0.787033</td>\n",
       "      <td>0.886496</td>\n",
       "      <td>0.833495</td>\n",
       "      <td>0.832840</td>\n",
       "      <td>0.031704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.225729</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>0.114539</td>\n",
       "      <td>0.004058</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.3, 'min_samples_leaf': 10, ...</td>\n",
       "      <td>0.687495</td>\n",
       "      <td>0.767501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.528931</td>\n",
       "      <td>0.188485</td>\n",
       "      <td>56</td>\n",
       "      <td>0.841179</td>\n",
       "      <td>0.833056</td>\n",
       "      <td>0.802476</td>\n",
       "      <td>0.888713</td>\n",
       "      <td>0.852684</td>\n",
       "      <td>0.843621</td>\n",
       "      <td>0.028021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.065980</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>0.118202</td>\n",
       "      <td>0.002722</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.3, 'min_samples_leaf': 25, ...</td>\n",
       "      <td>0.603330</td>\n",
       "      <td>0.660520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413995</td>\n",
       "      <td>0.247753</td>\n",
       "      <td>80</td>\n",
       "      <td>0.761561</td>\n",
       "      <td>0.706936</td>\n",
       "      <td>0.685565</td>\n",
       "      <td>0.761096</td>\n",
       "      <td>0.644721</td>\n",
       "      <td>0.711976</td>\n",
       "      <td>0.044984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.178954</td>\n",
       "      <td>0.019550</td>\n",
       "      <td>0.116222</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.3, 'min_samples_leaf': 25, ...</td>\n",
       "      <td>0.665164</td>\n",
       "      <td>0.674705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467122</td>\n",
       "      <td>0.172813</td>\n",
       "      <td>75</td>\n",
       "      <td>0.755445</td>\n",
       "      <td>0.705453</td>\n",
       "      <td>0.676352</td>\n",
       "      <td>0.810485</td>\n",
       "      <td>0.705113</td>\n",
       "      <td>0.730570</td>\n",
       "      <td>0.047379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.218368</td>\n",
       "      <td>0.010467</td>\n",
       "      <td>0.113657</td>\n",
       "      <td>0.006036</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.3, 'min_samples_leaf': 25, ...</td>\n",
       "      <td>0.592277</td>\n",
       "      <td>0.671321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417997</td>\n",
       "      <td>0.180965</td>\n",
       "      <td>79</td>\n",
       "      <td>0.737118</td>\n",
       "      <td>0.712036</td>\n",
       "      <td>0.671091</td>\n",
       "      <td>0.792313</td>\n",
       "      <td>0.717571</td>\n",
       "      <td>0.726026</td>\n",
       "      <td>0.039502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.089847</td>\n",
       "      <td>0.009647</td>\n",
       "      <td>0.125597</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.3, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.532917</td>\n",
       "      <td>0.557677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231508</td>\n",
       "      <td>0.272583</td>\n",
       "      <td>102</td>\n",
       "      <td>0.602504</td>\n",
       "      <td>0.586683</td>\n",
       "      <td>0.519287</td>\n",
       "      <td>0.603996</td>\n",
       "      <td>0.599423</td>\n",
       "      <td>0.582379</td>\n",
       "      <td>0.032131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.229686</td>\n",
       "      <td>0.037299</td>\n",
       "      <td>0.116645</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.3, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.559704</td>\n",
       "      <td>0.509066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247080</td>\n",
       "      <td>0.259738</td>\n",
       "      <td>101</td>\n",
       "      <td>0.635015</td>\n",
       "      <td>0.568703</td>\n",
       "      <td>0.543459</td>\n",
       "      <td>0.669988</td>\n",
       "      <td>0.589701</td>\n",
       "      <td>0.601373</td>\n",
       "      <td>0.045601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.293850</td>\n",
       "      <td>0.050967</td>\n",
       "      <td>0.117440</td>\n",
       "      <td>0.006077</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.3, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.536424</td>\n",
       "      <td>0.551428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249258</td>\n",
       "      <td>0.271703</td>\n",
       "      <td>100</td>\n",
       "      <td>0.624974</td>\n",
       "      <td>0.589398</td>\n",
       "      <td>0.530887</td>\n",
       "      <td>0.667675</td>\n",
       "      <td>0.562923</td>\n",
       "      <td>0.595171</td>\n",
       "      <td>0.047646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.075326</td>\n",
       "      <td>0.009287</td>\n",
       "      <td>0.129144</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.763077</td>\n",
       "      <td>0.842206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628259</td>\n",
       "      <td>0.228532</td>\n",
       "      <td>20</td>\n",
       "      <td>0.973284</td>\n",
       "      <td>0.973462</td>\n",
       "      <td>0.967604</td>\n",
       "      <td>0.977620</td>\n",
       "      <td>0.982400</td>\n",
       "      <td>0.974874</td>\n",
       "      <td>0.004931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.240963</td>\n",
       "      <td>0.031615</td>\n",
       "      <td>0.122963</td>\n",
       "      <td>0.009887</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.758610</td>\n",
       "      <td>0.862853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.656292</td>\n",
       "      <td>0.182968</td>\n",
       "      <td>8</td>\n",
       "      <td>0.982920</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.978699</td>\n",
       "      <td>0.986612</td>\n",
       "      <td>0.983420</td>\n",
       "      <td>0.982045</td>\n",
       "      <td>0.003059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.283978</td>\n",
       "      <td>0.024461</td>\n",
       "      <td>0.122646</td>\n",
       "      <td>0.008844</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.766007</td>\n",
       "      <td>0.867278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.650958</td>\n",
       "      <td>0.185087</td>\n",
       "      <td>10</td>\n",
       "      <td>0.983763</td>\n",
       "      <td>0.982046</td>\n",
       "      <td>0.978489</td>\n",
       "      <td>0.987217</td>\n",
       "      <td>0.983413</td>\n",
       "      <td>0.982986</td>\n",
       "      <td>0.002821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.074310</td>\n",
       "      <td>0.003368</td>\n",
       "      <td>0.115542</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.773005</td>\n",
       "      <td>0.841348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565203</td>\n",
       "      <td>0.240084</td>\n",
       "      <td>49</td>\n",
       "      <td>0.922491</td>\n",
       "      <td>0.907676</td>\n",
       "      <td>0.887939</td>\n",
       "      <td>0.940290</td>\n",
       "      <td>0.907554</td>\n",
       "      <td>0.913190</td>\n",
       "      <td>0.017440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.202093</td>\n",
       "      <td>0.030205</td>\n",
       "      <td>0.117918</td>\n",
       "      <td>0.008517</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.753818</td>\n",
       "      <td>0.869190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622839</td>\n",
       "      <td>0.187284</td>\n",
       "      <td>27</td>\n",
       "      <td>0.923924</td>\n",
       "      <td>0.911253</td>\n",
       "      <td>0.903611</td>\n",
       "      <td>0.950099</td>\n",
       "      <td>0.922460</td>\n",
       "      <td>0.922269</td>\n",
       "      <td>0.015791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.284329</td>\n",
       "      <td>0.031211</td>\n",
       "      <td>0.114525</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.758558</td>\n",
       "      <td>0.865411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639242</td>\n",
       "      <td>0.179629</td>\n",
       "      <td>17</td>\n",
       "      <td>0.928356</td>\n",
       "      <td>0.915713</td>\n",
       "      <td>0.903464</td>\n",
       "      <td>0.951279</td>\n",
       "      <td>0.919976</td>\n",
       "      <td>0.923757</td>\n",
       "      <td>0.015934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.075954</td>\n",
       "      <td>0.008687</td>\n",
       "      <td>0.130207</td>\n",
       "      <td>0.005176</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 10, ...</td>\n",
       "      <td>0.748413</td>\n",
       "      <td>0.880480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.222670</td>\n",
       "      <td>41</td>\n",
       "      <td>0.876976</td>\n",
       "      <td>0.858811</td>\n",
       "      <td>0.839262</td>\n",
       "      <td>0.915607</td>\n",
       "      <td>0.863042</td>\n",
       "      <td>0.870740</td>\n",
       "      <td>0.025473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.206396</td>\n",
       "      <td>0.030345</td>\n",
       "      <td>0.117638</td>\n",
       "      <td>0.003295</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 10, ...</td>\n",
       "      <td>0.768864</td>\n",
       "      <td>0.865847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616423</td>\n",
       "      <td>0.193692</td>\n",
       "      <td>32</td>\n",
       "      <td>0.882471</td>\n",
       "      <td>0.861365</td>\n",
       "      <td>0.837913</td>\n",
       "      <td>0.923109</td>\n",
       "      <td>0.878646</td>\n",
       "      <td>0.876701</td>\n",
       "      <td>0.028037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.236106</td>\n",
       "      <td>0.017135</td>\n",
       "      <td>0.123018</td>\n",
       "      <td>0.008519</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 10, ...</td>\n",
       "      <td>0.762437</td>\n",
       "      <td>0.862938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617802</td>\n",
       "      <td>0.187775</td>\n",
       "      <td>31</td>\n",
       "      <td>0.879611</td>\n",
       "      <td>0.859991</td>\n",
       "      <td>0.839686</td>\n",
       "      <td>0.924737</td>\n",
       "      <td>0.876477</td>\n",
       "      <td>0.876100</td>\n",
       "      <td>0.028155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.092711</td>\n",
       "      <td>0.008148</td>\n",
       "      <td>0.117769</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.7</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 25, ...</td>\n",
       "      <td>0.755090</td>\n",
       "      <td>0.798996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489233</td>\n",
       "      <td>0.304022</td>\n",
       "      <td>72</td>\n",
       "      <td>0.798671</td>\n",
       "      <td>0.769237</td>\n",
       "      <td>0.743812</td>\n",
       "      <td>0.849842</td>\n",
       "      <td>0.775558</td>\n",
       "      <td>0.787424</td>\n",
       "      <td>0.035766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.201251</td>\n",
       "      <td>0.045144</td>\n",
       "      <td>0.113547</td>\n",
       "      <td>0.005540</td>\n",
       "      <td>0.7</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 25, ...</td>\n",
       "      <td>0.739721</td>\n",
       "      <td>0.793334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534994</td>\n",
       "      <td>0.223024</td>\n",
       "      <td>53</td>\n",
       "      <td>0.795057</td>\n",
       "      <td>0.772389</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.838113</td>\n",
       "      <td>0.784953</td>\n",
       "      <td>0.787309</td>\n",
       "      <td>0.030242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.265390</td>\n",
       "      <td>0.065104</td>\n",
       "      <td>0.118577</td>\n",
       "      <td>0.009123</td>\n",
       "      <td>0.7</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 25, ...</td>\n",
       "      <td>0.718975</td>\n",
       "      <td>0.801343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525618</td>\n",
       "      <td>0.227599</td>\n",
       "      <td>57</td>\n",
       "      <td>0.800355</td>\n",
       "      <td>0.770430</td>\n",
       "      <td>0.740034</td>\n",
       "      <td>0.844797</td>\n",
       "      <td>0.784935</td>\n",
       "      <td>0.788110</td>\n",
       "      <td>0.034633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.073185</td>\n",
       "      <td>0.026278</td>\n",
       "      <td>0.120960</td>\n",
       "      <td>0.009316</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.545262</td>\n",
       "      <td>0.695668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276567</td>\n",
       "      <td>0.352102</td>\n",
       "      <td>98</td>\n",
       "      <td>0.667223</td>\n",
       "      <td>0.666032</td>\n",
       "      <td>0.596484</td>\n",
       "      <td>0.728867</td>\n",
       "      <td>0.656995</td>\n",
       "      <td>0.663120</td>\n",
       "      <td>0.042014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.188863</td>\n",
       "      <td>0.016729</td>\n",
       "      <td>0.121123</td>\n",
       "      <td>0.007024</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.592252</td>\n",
       "      <td>0.708058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338495</td>\n",
       "      <td>0.306622</td>\n",
       "      <td>87</td>\n",
       "      <td>0.681153</td>\n",
       "      <td>0.674112</td>\n",
       "      <td>0.600622</td>\n",
       "      <td>0.746670</td>\n",
       "      <td>0.681177</td>\n",
       "      <td>0.676747</td>\n",
       "      <td>0.046325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.211631</td>\n",
       "      <td>0.009279</td>\n",
       "      <td>0.114067</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.622963</td>\n",
       "      <td>0.699486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331433</td>\n",
       "      <td>0.323017</td>\n",
       "      <td>92</td>\n",
       "      <td>0.685834</td>\n",
       "      <td>0.664311</td>\n",
       "      <td>0.608311</td>\n",
       "      <td>0.739096</td>\n",
       "      <td>0.671836</td>\n",
       "      <td>0.673877</td>\n",
       "      <td>0.041931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.067919</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.123010</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.756370</td>\n",
       "      <td>0.861020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658000</td>\n",
       "      <td>0.161479</td>\n",
       "      <td>6</td>\n",
       "      <td>0.979567</td>\n",
       "      <td>0.969565</td>\n",
       "      <td>0.971386</td>\n",
       "      <td>0.979468</td>\n",
       "      <td>0.974174</td>\n",
       "      <td>0.974832</td>\n",
       "      <td>0.004098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.196207</td>\n",
       "      <td>0.008335</td>\n",
       "      <td>0.114586</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.747750</td>\n",
       "      <td>0.854856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627850</td>\n",
       "      <td>0.198822</td>\n",
       "      <td>21</td>\n",
       "      <td>0.985870</td>\n",
       "      <td>0.982107</td>\n",
       "      <td>0.979956</td>\n",
       "      <td>0.986754</td>\n",
       "      <td>0.980199</td>\n",
       "      <td>0.982977</td>\n",
       "      <td>0.002837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.286556</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.113007</td>\n",
       "      <td>0.002647</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.762136</td>\n",
       "      <td>0.865524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645210</td>\n",
       "      <td>0.187350</td>\n",
       "      <td>13</td>\n",
       "      <td>0.985415</td>\n",
       "      <td>0.980815</td>\n",
       "      <td>0.980638</td>\n",
       "      <td>0.986518</td>\n",
       "      <td>0.983668</td>\n",
       "      <td>0.983411</td>\n",
       "      <td>0.002374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.061716</td>\n",
       "      <td>0.018731</td>\n",
       "      <td>0.114832</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.738823</td>\n",
       "      <td>0.858937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613353</td>\n",
       "      <td>0.192895</td>\n",
       "      <td>34</td>\n",
       "      <td>0.920567</td>\n",
       "      <td>0.900366</td>\n",
       "      <td>0.889665</td>\n",
       "      <td>0.941149</td>\n",
       "      <td>0.921813</td>\n",
       "      <td>0.914712</td>\n",
       "      <td>0.017982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.214056</td>\n",
       "      <td>0.020031</td>\n",
       "      <td>0.122615</td>\n",
       "      <td>0.006762</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.766517</td>\n",
       "      <td>0.864810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616407</td>\n",
       "      <td>0.208017</td>\n",
       "      <td>33</td>\n",
       "      <td>0.921104</td>\n",
       "      <td>0.918827</td>\n",
       "      <td>0.904033</td>\n",
       "      <td>0.947117</td>\n",
       "      <td>0.917134</td>\n",
       "      <td>0.921643</td>\n",
       "      <td>0.014054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.246049</td>\n",
       "      <td>0.016695</td>\n",
       "      <td>0.112065</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.761560</td>\n",
       "      <td>0.871962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643844</td>\n",
       "      <td>0.177431</td>\n",
       "      <td>14</td>\n",
       "      <td>0.927406</td>\n",
       "      <td>0.915968</td>\n",
       "      <td>0.909273</td>\n",
       "      <td>0.949805</td>\n",
       "      <td>0.920910</td>\n",
       "      <td>0.924672</td>\n",
       "      <td>0.013901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.074795</td>\n",
       "      <td>0.018083</td>\n",
       "      <td>0.120457</td>\n",
       "      <td>0.004901</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 10, ...</td>\n",
       "      <td>0.749149</td>\n",
       "      <td>0.862626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610302</td>\n",
       "      <td>0.208130</td>\n",
       "      <td>36</td>\n",
       "      <td>0.878744</td>\n",
       "      <td>0.854687</td>\n",
       "      <td>0.820612</td>\n",
       "      <td>0.918082</td>\n",
       "      <td>0.869014</td>\n",
       "      <td>0.868228</td>\n",
       "      <td>0.031772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.196627</td>\n",
       "      <td>0.062898</td>\n",
       "      <td>0.119154</td>\n",
       "      <td>0.009361</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 10, ...</td>\n",
       "      <td>0.760109</td>\n",
       "      <td>0.870574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623396</td>\n",
       "      <td>0.195694</td>\n",
       "      <td>26</td>\n",
       "      <td>0.879726</td>\n",
       "      <td>0.866243</td>\n",
       "      <td>0.845834</td>\n",
       "      <td>0.919623</td>\n",
       "      <td>0.869683</td>\n",
       "      <td>0.876222</td>\n",
       "      <td>0.024338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.230914</td>\n",
       "      <td>0.018446</td>\n",
       "      <td>0.123677</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 10, ...</td>\n",
       "      <td>0.758325</td>\n",
       "      <td>0.876644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625135</td>\n",
       "      <td>0.185534</td>\n",
       "      <td>24</td>\n",
       "      <td>0.879001</td>\n",
       "      <td>0.864058</td>\n",
       "      <td>0.845023</td>\n",
       "      <td>0.922338</td>\n",
       "      <td>0.876087</td>\n",
       "      <td>0.877301</td>\n",
       "      <td>0.025495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.056601</td>\n",
       "      <td>0.015150</td>\n",
       "      <td>0.120494</td>\n",
       "      <td>0.008305</td>\n",
       "      <td>0.8</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 25, ...</td>\n",
       "      <td>0.715624</td>\n",
       "      <td>0.804508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508773</td>\n",
       "      <td>0.247693</td>\n",
       "      <td>65</td>\n",
       "      <td>0.792290</td>\n",
       "      <td>0.762195</td>\n",
       "      <td>0.740270</td>\n",
       "      <td>0.831953</td>\n",
       "      <td>0.788981</td>\n",
       "      <td>0.783138</td>\n",
       "      <td>0.030910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.170572</td>\n",
       "      <td>0.020588</td>\n",
       "      <td>0.117932</td>\n",
       "      <td>0.006328</td>\n",
       "      <td>0.8</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 25, ...</td>\n",
       "      <td>0.725472</td>\n",
       "      <td>0.812073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534432</td>\n",
       "      <td>0.227904</td>\n",
       "      <td>54</td>\n",
       "      <td>0.801781</td>\n",
       "      <td>0.774192</td>\n",
       "      <td>0.743366</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>0.790614</td>\n",
       "      <td>0.789798</td>\n",
       "      <td>0.031522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.224100</td>\n",
       "      <td>0.010379</td>\n",
       "      <td>0.115941</td>\n",
       "      <td>0.007047</td>\n",
       "      <td>0.8</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 25, ...</td>\n",
       "      <td>0.715248</td>\n",
       "      <td>0.799564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511819</td>\n",
       "      <td>0.252621</td>\n",
       "      <td>64</td>\n",
       "      <td>0.798851</td>\n",
       "      <td>0.779352</td>\n",
       "      <td>0.748965</td>\n",
       "      <td>0.839396</td>\n",
       "      <td>0.791095</td>\n",
       "      <td>0.791532</td>\n",
       "      <td>0.029343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.065130</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0.115423</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.580629</td>\n",
       "      <td>0.656539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314428</td>\n",
       "      <td>0.329626</td>\n",
       "      <td>96</td>\n",
       "      <td>0.673440</td>\n",
       "      <td>0.629222</td>\n",
       "      <td>0.609394</td>\n",
       "      <td>0.737399</td>\n",
       "      <td>0.659031</td>\n",
       "      <td>0.661697</td>\n",
       "      <td>0.043968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.202951</td>\n",
       "      <td>0.031702</td>\n",
       "      <td>0.117458</td>\n",
       "      <td>0.003889</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.550153</td>\n",
       "      <td>0.700312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332001</td>\n",
       "      <td>0.289881</td>\n",
       "      <td>91</td>\n",
       "      <td>0.679832</td>\n",
       "      <td>0.670667</td>\n",
       "      <td>0.603998</td>\n",
       "      <td>0.736006</td>\n",
       "      <td>0.670026</td>\n",
       "      <td>0.672106</td>\n",
       "      <td>0.041924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.286134</td>\n",
       "      <td>0.087012</td>\n",
       "      <td>0.115346</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.564734</td>\n",
       "      <td>0.704117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319167</td>\n",
       "      <td>0.315888</td>\n",
       "      <td>95</td>\n",
       "      <td>0.688908</td>\n",
       "      <td>0.659345</td>\n",
       "      <td>0.609321</td>\n",
       "      <td>0.740094</td>\n",
       "      <td>0.672415</td>\n",
       "      <td>0.674016</td>\n",
       "      <td>0.042406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.837242      1.532662         0.137253        0.047355   \n",
       "1         0.210489      0.010772         0.124109        0.007875   \n",
       "2         0.229695      0.009903         0.118321        0.006714   \n",
       "3         0.064809      0.016709         0.123606        0.008611   \n",
       "4         0.163775      0.027925         0.120218        0.002105   \n",
       "5         0.258020      0.040480         0.115124        0.002950   \n",
       "6         0.066811      0.007537         0.124494        0.007874   \n",
       "7         0.180930      0.033875         0.125031        0.007291   \n",
       "8         0.203821      0.014191         0.118143        0.005446   \n",
       "9         0.063172      0.001363         0.115274        0.001780   \n",
       "10        0.138356      0.030100         0.118105        0.010832   \n",
       "11        0.186424      0.030565         0.113383        0.002830   \n",
       "12        0.065988      0.001161         0.120357        0.003890   \n",
       "13        0.151941      0.004791         0.125338        0.009015   \n",
       "14        0.195693      0.014112         0.120310        0.006972   \n",
       "15        0.052620      0.005979         0.129201        0.008312   \n",
       "16        0.181846      0.013012         0.112755        0.002283   \n",
       "17        0.250643      0.025961         0.116473        0.005130   \n",
       "18        0.064086      0.013923         0.114012        0.002493   \n",
       "19        0.189303      0.010706         0.119096        0.007810   \n",
       "20        0.240738      0.032439         0.117394        0.009338   \n",
       "21        0.068770      0.003528         0.126971        0.006543   \n",
       "22        0.194144      0.016406         0.124128        0.010155   \n",
       "23        0.225729      0.024003         0.114539        0.004058   \n",
       "24        0.065980      0.003493         0.118202        0.002722   \n",
       "25        0.178954      0.019550         0.116222        0.002016   \n",
       "26        0.218368      0.010467         0.113657        0.006036   \n",
       "27        0.089847      0.009647         0.125597        0.006900   \n",
       "28        0.229686      0.037299         0.116645        0.003165   \n",
       "29        0.293850      0.050967         0.117440        0.006077   \n",
       "..             ...           ...              ...             ...   \n",
       "75        0.075326      0.009287         0.129144        0.007208   \n",
       "76        0.240963      0.031615         0.122963        0.009887   \n",
       "77        0.283978      0.024461         0.122646        0.008844   \n",
       "78        0.074310      0.003368         0.115542        0.001943   \n",
       "79        0.202093      0.030205         0.117918        0.008517   \n",
       "80        0.284329      0.031211         0.114525        0.002063   \n",
       "81        0.075954      0.008687         0.130207        0.005176   \n",
       "82        0.206396      0.030345         0.117638        0.003295   \n",
       "83        0.236106      0.017135         0.123018        0.008519   \n",
       "84        0.092711      0.008148         0.117769        0.001117   \n",
       "85        0.201251      0.045144         0.113547        0.005540   \n",
       "86        0.265390      0.065104         0.118577        0.009123   \n",
       "87        0.073185      0.026278         0.120960        0.009316   \n",
       "88        0.188863      0.016729         0.121123        0.007024   \n",
       "89        0.211631      0.009279         0.114067        0.001858   \n",
       "90        0.067919      0.005169         0.123010        0.004263   \n",
       "91        0.196207      0.008335         0.114586        0.000845   \n",
       "92        0.286556      0.028571         0.113007        0.002647   \n",
       "93        0.061716      0.018731         0.114832        0.002411   \n",
       "94        0.214056      0.020031         0.122615        0.006762   \n",
       "95        0.246049      0.016695         0.112065        0.001716   \n",
       "96        0.074795      0.018083         0.120457        0.004901   \n",
       "97        0.196627      0.062898         0.119154        0.009361   \n",
       "98        0.230914      0.018446         0.123677        0.006815   \n",
       "99        0.056601      0.015150         0.120494        0.008305   \n",
       "100       0.170572      0.020588         0.117932        0.006328   \n",
       "101       0.224100      0.010379         0.115941        0.007047   \n",
       "102       0.065130      0.003085         0.115423        0.002576   \n",
       "103       0.202951      0.031702         0.117458        0.003889   \n",
       "104       0.286134      0.087012         0.115346        0.005452   \n",
       "\n",
       "    param_max_features param_min_samples_leaf param_n_estimators  \\\n",
       "0                  0.2                      1                 10   \n",
       "1                  0.2                      1                 50   \n",
       "2                  0.2                      1                100   \n",
       "3                  0.2                      5                 10   \n",
       "4                  0.2                      5                 50   \n",
       "5                  0.2                      5                100   \n",
       "6                  0.2                     10                 10   \n",
       "7                  0.2                     10                 50   \n",
       "8                  0.2                     10                100   \n",
       "9                  0.2                     25                 10   \n",
       "10                 0.2                     25                 50   \n",
       "11                 0.2                     25                100   \n",
       "12                 0.2                     50                 10   \n",
       "13                 0.2                     50                 50   \n",
       "14                 0.2                     50                100   \n",
       "15                 0.3                      1                 10   \n",
       "16                 0.3                      1                 50   \n",
       "17                 0.3                      1                100   \n",
       "18                 0.3                      5                 10   \n",
       "19                 0.3                      5                 50   \n",
       "20                 0.3                      5                100   \n",
       "21                 0.3                     10                 10   \n",
       "22                 0.3                     10                 50   \n",
       "23                 0.3                     10                100   \n",
       "24                 0.3                     25                 10   \n",
       "25                 0.3                     25                 50   \n",
       "26                 0.3                     25                100   \n",
       "27                 0.3                     50                 10   \n",
       "28                 0.3                     50                 50   \n",
       "29                 0.3                     50                100   \n",
       "..                 ...                    ...                ...   \n",
       "75                 0.7                      1                 10   \n",
       "76                 0.7                      1                 50   \n",
       "77                 0.7                      1                100   \n",
       "78                 0.7                      5                 10   \n",
       "79                 0.7                      5                 50   \n",
       "80                 0.7                      5                100   \n",
       "81                 0.7                     10                 10   \n",
       "82                 0.7                     10                 50   \n",
       "83                 0.7                     10                100   \n",
       "84                 0.7                     25                 10   \n",
       "85                 0.7                     25                 50   \n",
       "86                 0.7                     25                100   \n",
       "87                 0.7                     50                 10   \n",
       "88                 0.7                     50                 50   \n",
       "89                 0.7                     50                100   \n",
       "90                 0.8                      1                 10   \n",
       "91                 0.8                      1                 50   \n",
       "92                 0.8                      1                100   \n",
       "93                 0.8                      5                 10   \n",
       "94                 0.8                      5                 50   \n",
       "95                 0.8                      5                100   \n",
       "96                 0.8                     10                 10   \n",
       "97                 0.8                     10                 50   \n",
       "98                 0.8                     10                100   \n",
       "99                 0.8                     25                 10   \n",
       "100                0.8                     25                 50   \n",
       "101                0.8                     25                100   \n",
       "102                0.8                     50                 10   \n",
       "103                0.8                     50                 50   \n",
       "104                0.8                     50                100   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'max_features': 0.2, 'min_samples_leaf': 1, '...           0.664692   \n",
       "1    {'max_features': 0.2, 'min_samples_leaf': 1, '...           0.725826   \n",
       "2    {'max_features': 0.2, 'min_samples_leaf': 1, '...           0.690542   \n",
       "3    {'max_features': 0.2, 'min_samples_leaf': 5, '...           0.552088   \n",
       "4    {'max_features': 0.2, 'min_samples_leaf': 5, '...           0.672767   \n",
       "5    {'max_features': 0.2, 'min_samples_leaf': 5, '...           0.669864   \n",
       "6    {'max_features': 0.2, 'min_samples_leaf': 10, ...           0.630756   \n",
       "7    {'max_features': 0.2, 'min_samples_leaf': 10, ...           0.650407   \n",
       "8    {'max_features': 0.2, 'min_samples_leaf': 10, ...           0.612149   \n",
       "9    {'max_features': 0.2, 'min_samples_leaf': 25, ...           0.502506   \n",
       "10   {'max_features': 0.2, 'min_samples_leaf': 25, ...           0.497843   \n",
       "11   {'max_features': 0.2, 'min_samples_leaf': 25, ...           0.545118   \n",
       "12   {'max_features': 0.2, 'min_samples_leaf': 50, ...           0.377553   \n",
       "13   {'max_features': 0.2, 'min_samples_leaf': 50, ...           0.381621   \n",
       "14   {'max_features': 0.2, 'min_samples_leaf': 50, ...           0.371903   \n",
       "15   {'max_features': 0.3, 'min_samples_leaf': 1, '...           0.719471   \n",
       "16   {'max_features': 0.3, 'min_samples_leaf': 1, '...           0.763000   \n",
       "17   {'max_features': 0.3, 'min_samples_leaf': 1, '...           0.745868   \n",
       "18   {'max_features': 0.3, 'min_samples_leaf': 5, '...           0.757417   \n",
       "19   {'max_features': 0.3, 'min_samples_leaf': 5, '...           0.699674   \n",
       "20   {'max_features': 0.3, 'min_samples_leaf': 5, '...           0.713888   \n",
       "21   {'max_features': 0.3, 'min_samples_leaf': 10, ...           0.717652   \n",
       "22   {'max_features': 0.3, 'min_samples_leaf': 10, ...           0.712364   \n",
       "23   {'max_features': 0.3, 'min_samples_leaf': 10, ...           0.687495   \n",
       "24   {'max_features': 0.3, 'min_samples_leaf': 25, ...           0.603330   \n",
       "25   {'max_features': 0.3, 'min_samples_leaf': 25, ...           0.665164   \n",
       "26   {'max_features': 0.3, 'min_samples_leaf': 25, ...           0.592277   \n",
       "27   {'max_features': 0.3, 'min_samples_leaf': 50, ...           0.532917   \n",
       "28   {'max_features': 0.3, 'min_samples_leaf': 50, ...           0.559704   \n",
       "29   {'max_features': 0.3, 'min_samples_leaf': 50, ...           0.536424   \n",
       "..                                                 ...                ...   \n",
       "75   {'max_features': 0.7, 'min_samples_leaf': 1, '...           0.763077   \n",
       "76   {'max_features': 0.7, 'min_samples_leaf': 1, '...           0.758610   \n",
       "77   {'max_features': 0.7, 'min_samples_leaf': 1, '...           0.766007   \n",
       "78   {'max_features': 0.7, 'min_samples_leaf': 5, '...           0.773005   \n",
       "79   {'max_features': 0.7, 'min_samples_leaf': 5, '...           0.753818   \n",
       "80   {'max_features': 0.7, 'min_samples_leaf': 5, '...           0.758558   \n",
       "81   {'max_features': 0.7, 'min_samples_leaf': 10, ...           0.748413   \n",
       "82   {'max_features': 0.7, 'min_samples_leaf': 10, ...           0.768864   \n",
       "83   {'max_features': 0.7, 'min_samples_leaf': 10, ...           0.762437   \n",
       "84   {'max_features': 0.7, 'min_samples_leaf': 25, ...           0.755090   \n",
       "85   {'max_features': 0.7, 'min_samples_leaf': 25, ...           0.739721   \n",
       "86   {'max_features': 0.7, 'min_samples_leaf': 25, ...           0.718975   \n",
       "87   {'max_features': 0.7, 'min_samples_leaf': 50, ...           0.545262   \n",
       "88   {'max_features': 0.7, 'min_samples_leaf': 50, ...           0.592252   \n",
       "89   {'max_features': 0.7, 'min_samples_leaf': 50, ...           0.622963   \n",
       "90   {'max_features': 0.8, 'min_samples_leaf': 1, '...           0.756370   \n",
       "91   {'max_features': 0.8, 'min_samples_leaf': 1, '...           0.747750   \n",
       "92   {'max_features': 0.8, 'min_samples_leaf': 1, '...           0.762136   \n",
       "93   {'max_features': 0.8, 'min_samples_leaf': 5, '...           0.738823   \n",
       "94   {'max_features': 0.8, 'min_samples_leaf': 5, '...           0.766517   \n",
       "95   {'max_features': 0.8, 'min_samples_leaf': 5, '...           0.761560   \n",
       "96   {'max_features': 0.8, 'min_samples_leaf': 10, ...           0.749149   \n",
       "97   {'max_features': 0.8, 'min_samples_leaf': 10, ...           0.760109   \n",
       "98   {'max_features': 0.8, 'min_samples_leaf': 10, ...           0.758325   \n",
       "99   {'max_features': 0.8, 'min_samples_leaf': 25, ...           0.715624   \n",
       "100  {'max_features': 0.8, 'min_samples_leaf': 25, ...           0.725472   \n",
       "101  {'max_features': 0.8, 'min_samples_leaf': 25, ...           0.715248   \n",
       "102  {'max_features': 0.8, 'min_samples_leaf': 50, ...           0.580629   \n",
       "103  {'max_features': 0.8, 'min_samples_leaf': 50, ...           0.550153   \n",
       "104  {'max_features': 0.8, 'min_samples_leaf': 50, ...           0.564734   \n",
       "\n",
       "     split1_test_score       ...         mean_test_score  std_test_score  \\\n",
       "0             0.714682       ...                0.374030        0.490833   \n",
       "1             0.791020       ...                0.545084        0.283051   \n",
       "2             0.758533       ...                0.535446        0.236550   \n",
       "3             0.762288       ...                0.512766        0.172448   \n",
       "4             0.751675       ...                0.492090        0.215501   \n",
       "5             0.740851       ...                0.473058        0.236209   \n",
       "6             0.697546       ...                0.494386        0.151891   \n",
       "7             0.714605       ...                0.431585        0.249814   \n",
       "8             0.684267       ...                0.467557        0.154338   \n",
       "9             0.670466       ...                0.263809        0.309177   \n",
       "10            0.668642       ...                0.348925        0.220361   \n",
       "11            0.611298       ...                0.326835        0.223461   \n",
       "12            0.456916       ...                0.187798        0.229433   \n",
       "13            0.489266       ...                0.152992        0.283435   \n",
       "14            0.514043       ...                0.128670        0.308399   \n",
       "15            0.835451       ...                0.567538        0.254841   \n",
       "16            0.850329       ...                0.585556        0.256305   \n",
       "17            0.837911       ...                0.601383        0.244004   \n",
       "18            0.809014       ...                0.584984        0.217343   \n",
       "19            0.824981       ...                0.589558        0.182520   \n",
       "20            0.836990       ...                0.586528        0.196387   \n",
       "21            0.726116       ...                0.465864        0.236407   \n",
       "22            0.777920       ...                0.531443        0.191403   \n",
       "23            0.767501       ...                0.528931        0.188485   \n",
       "24            0.660520       ...                0.413995        0.247753   \n",
       "25            0.674705       ...                0.467122        0.172813   \n",
       "26            0.671321       ...                0.417997        0.180965   \n",
       "27            0.557677       ...                0.231508        0.272583   \n",
       "28            0.509066       ...                0.247080        0.259738   \n",
       "29            0.551428       ...                0.249258        0.271703   \n",
       "..                 ...       ...                     ...             ...   \n",
       "75            0.842206       ...                0.628259        0.228532   \n",
       "76            0.862853       ...                0.656292        0.182968   \n",
       "77            0.867278       ...                0.650958        0.185087   \n",
       "78            0.841348       ...                0.565203        0.240084   \n",
       "79            0.869190       ...                0.622839        0.187284   \n",
       "80            0.865411       ...                0.639242        0.179629   \n",
       "81            0.880480       ...                0.601496        0.222670   \n",
       "82            0.865847       ...                0.616423        0.193692   \n",
       "83            0.862938       ...                0.617802        0.187775   \n",
       "84            0.798996       ...                0.489233        0.304022   \n",
       "85            0.793334       ...                0.534994        0.223024   \n",
       "86            0.801343       ...                0.525618        0.227599   \n",
       "87            0.695668       ...                0.276567        0.352102   \n",
       "88            0.708058       ...                0.338495        0.306622   \n",
       "89            0.699486       ...                0.331433        0.323017   \n",
       "90            0.861020       ...                0.658000        0.161479   \n",
       "91            0.854856       ...                0.627850        0.198822   \n",
       "92            0.865524       ...                0.645210        0.187350   \n",
       "93            0.858937       ...                0.613353        0.192895   \n",
       "94            0.864810       ...                0.616407        0.208017   \n",
       "95            0.871962       ...                0.643844        0.177431   \n",
       "96            0.862626       ...                0.610302        0.208130   \n",
       "97            0.870574       ...                0.623396        0.195694   \n",
       "98            0.876644       ...                0.625135        0.185534   \n",
       "99            0.804508       ...                0.508773        0.247693   \n",
       "100           0.812073       ...                0.534432        0.227904   \n",
       "101           0.799564       ...                0.511819        0.252621   \n",
       "102           0.656539       ...                0.314428        0.329626   \n",
       "103           0.700312       ...                0.332001        0.289881   \n",
       "104           0.704117       ...                0.319167        0.315888   \n",
       "\n",
       "     rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                 81            0.975065            0.967663   \n",
       "1                 50            0.978808            0.974994   \n",
       "2                 52            0.979991            0.978241   \n",
       "3                 63            0.874961            0.871851   \n",
       "4                 71            0.881289            0.851465   \n",
       "5                 73            0.883017            0.863584   \n",
       "6                 70            0.798015            0.784666   \n",
       "7                 78            0.819102            0.783502   \n",
       "8                 74            0.801168            0.790448   \n",
       "9                 99            0.686664            0.678674   \n",
       "10                83            0.678063            0.688901   \n",
       "11                94            0.685961            0.666525   \n",
       "12               103            0.538313            0.515577   \n",
       "13               104            0.550696            0.524976   \n",
       "14               105            0.552130            0.556581   \n",
       "15                48            0.964617            0.979811   \n",
       "16                45            0.981415            0.980420   \n",
       "17                42            0.983350            0.982144   \n",
       "18                46            0.902460            0.886497   \n",
       "19                43            0.906722            0.885126   \n",
       "20                44            0.893805            0.889065   \n",
       "21                76            0.828205            0.805481   \n",
       "22                55            0.831020            0.826158   \n",
       "23                56            0.841179            0.833056   \n",
       "24                80            0.761561            0.706936   \n",
       "25                75            0.755445            0.705453   \n",
       "26                79            0.737118            0.712036   \n",
       "27               102            0.602504            0.586683   \n",
       "28               101            0.635015            0.568703   \n",
       "29               100            0.624974            0.589398   \n",
       "..               ...                 ...                 ...   \n",
       "75                20            0.973284            0.973462   \n",
       "76                 8            0.982920            0.978571   \n",
       "77                10            0.983763            0.982046   \n",
       "78                49            0.922491            0.907676   \n",
       "79                27            0.923924            0.911253   \n",
       "80                17            0.928356            0.915713   \n",
       "81                41            0.876976            0.858811   \n",
       "82                32            0.882471            0.861365   \n",
       "83                31            0.879611            0.859991   \n",
       "84                72            0.798671            0.769237   \n",
       "85                53            0.795057            0.772389   \n",
       "86                57            0.800355            0.770430   \n",
       "87                98            0.667223            0.666032   \n",
       "88                87            0.681153            0.674112   \n",
       "89                92            0.685834            0.664311   \n",
       "90                 6            0.979567            0.969565   \n",
       "91                21            0.985870            0.982107   \n",
       "92                13            0.985415            0.980815   \n",
       "93                34            0.920567            0.900366   \n",
       "94                33            0.921104            0.918827   \n",
       "95                14            0.927406            0.915968   \n",
       "96                36            0.878744            0.854687   \n",
       "97                26            0.879726            0.866243   \n",
       "98                24            0.879001            0.864058   \n",
       "99                65            0.792290            0.762195   \n",
       "100               54            0.801781            0.774192   \n",
       "101               64            0.798851            0.779352   \n",
       "102               96            0.673440            0.629222   \n",
       "103               91            0.679832            0.670667   \n",
       "104               95            0.688908            0.659345   \n",
       "\n",
       "     split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0              0.956488            0.979908            0.969051   \n",
       "1              0.970690            0.984484            0.982326   \n",
       "2              0.975416            0.984952            0.981163   \n",
       "3              0.782946            0.896750            0.843260   \n",
       "4              0.856600            0.905478            0.877454   \n",
       "5              0.838940            0.912063            0.876536   \n",
       "6              0.717407            0.864836            0.735879   \n",
       "7              0.765602            0.850413            0.789898   \n",
       "8              0.744392            0.868705            0.804875   \n",
       "9              0.545963            0.749778            0.638056   \n",
       "10             0.634359            0.767409            0.635591   \n",
       "11             0.605300            0.761327            0.659035   \n",
       "12             0.515177            0.631410            0.596423   \n",
       "13             0.484821            0.648215            0.501515   \n",
       "14             0.485621            0.620239            0.477319   \n",
       "15             0.957186            0.980428            0.975036   \n",
       "16             0.976040            0.985544            0.979260   \n",
       "17             0.975326            0.986775            0.982811   \n",
       "18             0.869034            0.918388            0.875634   \n",
       "19             0.873334            0.934719            0.900227   \n",
       "20             0.866288            0.928838            0.903172   \n",
       "21             0.768986            0.855292            0.818992   \n",
       "22             0.787033            0.886496            0.833495   \n",
       "23             0.802476            0.888713            0.852684   \n",
       "24             0.685565            0.761096            0.644721   \n",
       "25             0.676352            0.810485            0.705113   \n",
       "26             0.671091            0.792313            0.717571   \n",
       "27             0.519287            0.603996            0.599423   \n",
       "28             0.543459            0.669988            0.589701   \n",
       "29             0.530887            0.667675            0.562923   \n",
       "..                  ...                 ...                 ...   \n",
       "75             0.967604            0.977620            0.982400   \n",
       "76             0.978699            0.986612            0.983420   \n",
       "77             0.978489            0.987217            0.983413   \n",
       "78             0.887939            0.940290            0.907554   \n",
       "79             0.903611            0.950099            0.922460   \n",
       "80             0.903464            0.951279            0.919976   \n",
       "81             0.839262            0.915607            0.863042   \n",
       "82             0.837913            0.923109            0.878646   \n",
       "83             0.839686            0.924737            0.876477   \n",
       "84             0.743812            0.849842            0.775558   \n",
       "85             0.746032            0.838113            0.784953   \n",
       "86             0.740034            0.844797            0.784935   \n",
       "87             0.596484            0.728867            0.656995   \n",
       "88             0.600622            0.746670            0.681177   \n",
       "89             0.608311            0.739096            0.671836   \n",
       "90             0.971386            0.979468            0.974174   \n",
       "91             0.979956            0.986754            0.980199   \n",
       "92             0.980638            0.986518            0.983668   \n",
       "93             0.889665            0.941149            0.921813   \n",
       "94             0.904033            0.947117            0.917134   \n",
       "95             0.909273            0.949805            0.920910   \n",
       "96             0.820612            0.918082            0.869014   \n",
       "97             0.845834            0.919623            0.869683   \n",
       "98             0.845023            0.922338            0.876087   \n",
       "99             0.740270            0.831953            0.788981   \n",
       "100            0.743366            0.839036            0.790614   \n",
       "101            0.748965            0.839396            0.791095   \n",
       "102            0.609394            0.737399            0.659031   \n",
       "103            0.603998            0.736006            0.670026   \n",
       "104            0.609321            0.740094            0.672415   \n",
       "\n",
       "     mean_train_score  std_train_score  \n",
       "0            0.969635         0.007901  \n",
       "1            0.978260         0.004971  \n",
       "2            0.979953         0.003161  \n",
       "3            0.853954         0.039369  \n",
       "4            0.874457         0.019316  \n",
       "5            0.874828         0.023961  \n",
       "6            0.780161         0.051784  \n",
       "7            0.801703         0.029831  \n",
       "8            0.801918         0.039776  \n",
       "9            0.659827         0.067239  \n",
       "10           0.680865         0.048528  \n",
       "11           0.675630         0.050508  \n",
       "12           0.559380         0.046641  \n",
       "13           0.542045         0.057542  \n",
       "14           0.538378         0.052409  \n",
       "15           0.971416         0.009094  \n",
       "16           0.980536         0.003089  \n",
       "17           0.982081         0.003737  \n",
       "18           0.890403         0.017992  \n",
       "19           0.900026         0.020895  \n",
       "20           0.896234         0.020323  \n",
       "21           0.815391         0.028358  \n",
       "22           0.832840         0.031704  \n",
       "23           0.843621         0.028021  \n",
       "24           0.711976         0.044984  \n",
       "25           0.730570         0.047379  \n",
       "26           0.726026         0.039502  \n",
       "27           0.582379         0.032131  \n",
       "28           0.601373         0.045601  \n",
       "29           0.595171         0.047646  \n",
       "..                ...              ...  \n",
       "75           0.974874         0.004931  \n",
       "76           0.982045         0.003059  \n",
       "77           0.982986         0.002821  \n",
       "78           0.913190         0.017440  \n",
       "79           0.922269         0.015791  \n",
       "80           0.923757         0.015934  \n",
       "81           0.870740         0.025473  \n",
       "82           0.876701         0.028037  \n",
       "83           0.876100         0.028155  \n",
       "84           0.787424         0.035766  \n",
       "85           0.787309         0.030242  \n",
       "86           0.788110         0.034633  \n",
       "87           0.663120         0.042014  \n",
       "88           0.676747         0.046325  \n",
       "89           0.673877         0.041931  \n",
       "90           0.974832         0.004098  \n",
       "91           0.982977         0.002837  \n",
       "92           0.983411         0.002374  \n",
       "93           0.914712         0.017982  \n",
       "94           0.921643         0.014054  \n",
       "95           0.924672         0.013901  \n",
       "96           0.868228         0.031772  \n",
       "97           0.876222         0.024338  \n",
       "98           0.877301         0.025495  \n",
       "99           0.783138         0.030910  \n",
       "100          0.789798         0.031522  \n",
       "101          0.791532         0.029343  \n",
       "102          0.661697         0.043968  \n",
       "103          0.672106         0.041924  \n",
       "104          0.674016         0.042406  \n",
       "\n",
       "[105 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convenient to load this into a dataframe, to better view its results\n",
    "grid_results = pd.DataFrame(Grid.cv_results_)\n",
    "grid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.075773</td>\n",
       "      <td>0.007419</td>\n",
       "      <td>0.127579</td>\n",
       "      <td>0.012758</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.4, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.759879</td>\n",
       "      <td>0.844738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673682</td>\n",
       "      <td>0.153816</td>\n",
       "      <td>1</td>\n",
       "      <td>0.911802</td>\n",
       "      <td>0.909605</td>\n",
       "      <td>0.892976</td>\n",
       "      <td>0.936575</td>\n",
       "      <td>0.915583</td>\n",
       "      <td>0.913308</td>\n",
       "      <td>0.013971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.204946</td>\n",
       "      <td>0.014164</td>\n",
       "      <td>0.120121</td>\n",
       "      <td>0.007557</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.5, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.755386</td>\n",
       "      <td>0.863149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666336</td>\n",
       "      <td>0.184254</td>\n",
       "      <td>2</td>\n",
       "      <td>0.981631</td>\n",
       "      <td>0.978837</td>\n",
       "      <td>0.979893</td>\n",
       "      <td>0.986491</td>\n",
       "      <td>0.980832</td>\n",
       "      <td>0.981537</td>\n",
       "      <td>0.002647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.254692</td>\n",
       "      <td>0.012598</td>\n",
       "      <td>0.115289</td>\n",
       "      <td>0.006896</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.5, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.763938</td>\n",
       "      <td>0.860562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659012</td>\n",
       "      <td>0.180616</td>\n",
       "      <td>3</td>\n",
       "      <td>0.984083</td>\n",
       "      <td>0.983177</td>\n",
       "      <td>0.980008</td>\n",
       "      <td>0.987489</td>\n",
       "      <td>0.983567</td>\n",
       "      <td>0.983665</td>\n",
       "      <td>0.002384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.208347</td>\n",
       "      <td>0.022103</td>\n",
       "      <td>0.115135</td>\n",
       "      <td>0.005718</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.5, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.752754</td>\n",
       "      <td>0.856948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658619</td>\n",
       "      <td>0.155379</td>\n",
       "      <td>4</td>\n",
       "      <td>0.918081</td>\n",
       "      <td>0.913259</td>\n",
       "      <td>0.898575</td>\n",
       "      <td>0.945113</td>\n",
       "      <td>0.908076</td>\n",
       "      <td>0.916621</td>\n",
       "      <td>0.015645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.309309</td>\n",
       "      <td>0.045359</td>\n",
       "      <td>0.117833</td>\n",
       "      <td>0.007485</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.6, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.769179</td>\n",
       "      <td>0.866195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658172</td>\n",
       "      <td>0.185553</td>\n",
       "      <td>5</td>\n",
       "      <td>0.985434</td>\n",
       "      <td>0.980681</td>\n",
       "      <td>0.979287</td>\n",
       "      <td>0.987170</td>\n",
       "      <td>0.981918</td>\n",
       "      <td>0.982898</td>\n",
       "      <td>0.002953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.067919</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.123010</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.756370</td>\n",
       "      <td>0.861020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658000</td>\n",
       "      <td>0.161479</td>\n",
       "      <td>6</td>\n",
       "      <td>0.979567</td>\n",
       "      <td>0.969565</td>\n",
       "      <td>0.971386</td>\n",
       "      <td>0.979468</td>\n",
       "      <td>0.974174</td>\n",
       "      <td>0.974832</td>\n",
       "      <td>0.004098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.242313</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>0.115801</td>\n",
       "      <td>0.005669</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.6, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.759523</td>\n",
       "      <td>0.869465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657166</td>\n",
       "      <td>0.174786</td>\n",
       "      <td>7</td>\n",
       "      <td>0.923424</td>\n",
       "      <td>0.916723</td>\n",
       "      <td>0.897542</td>\n",
       "      <td>0.949119</td>\n",
       "      <td>0.916960</td>\n",
       "      <td>0.920753</td>\n",
       "      <td>0.016620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.240963</td>\n",
       "      <td>0.031615</td>\n",
       "      <td>0.122963</td>\n",
       "      <td>0.009887</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.758610</td>\n",
       "      <td>0.862853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.656292</td>\n",
       "      <td>0.182968</td>\n",
       "      <td>8</td>\n",
       "      <td>0.982920</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.978699</td>\n",
       "      <td>0.986612</td>\n",
       "      <td>0.983420</td>\n",
       "      <td>0.982045</td>\n",
       "      <td>0.003059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.261204</td>\n",
       "      <td>0.030451</td>\n",
       "      <td>0.116824</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.6, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.772119</td>\n",
       "      <td>0.865476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.653013</td>\n",
       "      <td>0.177449</td>\n",
       "      <td>9</td>\n",
       "      <td>0.984468</td>\n",
       "      <td>0.983222</td>\n",
       "      <td>0.978606</td>\n",
       "      <td>0.986031</td>\n",
       "      <td>0.980642</td>\n",
       "      <td>0.982594</td>\n",
       "      <td>0.002662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.283978</td>\n",
       "      <td>0.024461</td>\n",
       "      <td>0.122646</td>\n",
       "      <td>0.008844</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.766007</td>\n",
       "      <td>0.867278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.650958</td>\n",
       "      <td>0.185087</td>\n",
       "      <td>10</td>\n",
       "      <td>0.983763</td>\n",
       "      <td>0.982046</td>\n",
       "      <td>0.978489</td>\n",
       "      <td>0.987217</td>\n",
       "      <td>0.983413</td>\n",
       "      <td>0.982986</td>\n",
       "      <td>0.002821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.070690</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.121437</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.5, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.750575</td>\n",
       "      <td>0.827131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646574</td>\n",
       "      <td>0.161650</td>\n",
       "      <td>11</td>\n",
       "      <td>0.977724</td>\n",
       "      <td>0.972268</td>\n",
       "      <td>0.972245</td>\n",
       "      <td>0.980895</td>\n",
       "      <td>0.971573</td>\n",
       "      <td>0.974941</td>\n",
       "      <td>0.003713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.265492</td>\n",
       "      <td>0.039781</td>\n",
       "      <td>0.114958</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.4, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.765890</td>\n",
       "      <td>0.855205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646406</td>\n",
       "      <td>0.192223</td>\n",
       "      <td>12</td>\n",
       "      <td>0.984459</td>\n",
       "      <td>0.982595</td>\n",
       "      <td>0.979785</td>\n",
       "      <td>0.987855</td>\n",
       "      <td>0.982613</td>\n",
       "      <td>0.983461</td>\n",
       "      <td>0.002656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.286556</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.113007</td>\n",
       "      <td>0.002647</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.762136</td>\n",
       "      <td>0.865524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645210</td>\n",
       "      <td>0.187350</td>\n",
       "      <td>13</td>\n",
       "      <td>0.985415</td>\n",
       "      <td>0.980815</td>\n",
       "      <td>0.980638</td>\n",
       "      <td>0.986518</td>\n",
       "      <td>0.983668</td>\n",
       "      <td>0.983411</td>\n",
       "      <td>0.002374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.246049</td>\n",
       "      <td>0.016695</td>\n",
       "      <td>0.112065</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.761560</td>\n",
       "      <td>0.871962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643844</td>\n",
       "      <td>0.177431</td>\n",
       "      <td>14</td>\n",
       "      <td>0.927406</td>\n",
       "      <td>0.915968</td>\n",
       "      <td>0.909273</td>\n",
       "      <td>0.949805</td>\n",
       "      <td>0.920910</td>\n",
       "      <td>0.924672</td>\n",
       "      <td>0.013901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.263239</td>\n",
       "      <td>0.030875</td>\n",
       "      <td>0.126368</td>\n",
       "      <td>0.003090</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.5, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.753900</td>\n",
       "      <td>0.854616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.641711</td>\n",
       "      <td>0.179646</td>\n",
       "      <td>15</td>\n",
       "      <td>0.919956</td>\n",
       "      <td>0.912146</td>\n",
       "      <td>0.902405</td>\n",
       "      <td>0.948048</td>\n",
       "      <td>0.920031</td>\n",
       "      <td>0.920517</td>\n",
       "      <td>0.015209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.222796</td>\n",
       "      <td>0.010784</td>\n",
       "      <td>0.114300</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.4, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.750279</td>\n",
       "      <td>0.850314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.640562</td>\n",
       "      <td>0.178726</td>\n",
       "      <td>16</td>\n",
       "      <td>0.921521</td>\n",
       "      <td>0.906370</td>\n",
       "      <td>0.893999</td>\n",
       "      <td>0.946436</td>\n",
       "      <td>0.917688</td>\n",
       "      <td>0.917203</td>\n",
       "      <td>0.017488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.284329</td>\n",
       "      <td>0.031211</td>\n",
       "      <td>0.114525</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.758558</td>\n",
       "      <td>0.865411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639242</td>\n",
       "      <td>0.179629</td>\n",
       "      <td>17</td>\n",
       "      <td>0.928356</td>\n",
       "      <td>0.915713</td>\n",
       "      <td>0.903464</td>\n",
       "      <td>0.951279</td>\n",
       "      <td>0.919976</td>\n",
       "      <td>0.923757</td>\n",
       "      <td>0.015934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.073307</td>\n",
       "      <td>0.021726</td>\n",
       "      <td>0.113977</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.6, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.705933</td>\n",
       "      <td>0.869563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637882</td>\n",
       "      <td>0.172156</td>\n",
       "      <td>18</td>\n",
       "      <td>0.978501</td>\n",
       "      <td>0.976466</td>\n",
       "      <td>0.975755</td>\n",
       "      <td>0.980182</td>\n",
       "      <td>0.976018</td>\n",
       "      <td>0.977385</td>\n",
       "      <td>0.001699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.202776</td>\n",
       "      <td>0.006435</td>\n",
       "      <td>0.114657</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.6, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.768845</td>\n",
       "      <td>0.868330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.635577</td>\n",
       "      <td>0.208824</td>\n",
       "      <td>19</td>\n",
       "      <td>0.919234</td>\n",
       "      <td>0.910458</td>\n",
       "      <td>0.897865</td>\n",
       "      <td>0.948238</td>\n",
       "      <td>0.920949</td>\n",
       "      <td>0.919349</td>\n",
       "      <td>0.016600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.075326</td>\n",
       "      <td>0.009287</td>\n",
       "      <td>0.129144</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.763077</td>\n",
       "      <td>0.842206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628259</td>\n",
       "      <td>0.228532</td>\n",
       "      <td>20</td>\n",
       "      <td>0.973284</td>\n",
       "      <td>0.973462</td>\n",
       "      <td>0.967604</td>\n",
       "      <td>0.977620</td>\n",
       "      <td>0.982400</td>\n",
       "      <td>0.974874</td>\n",
       "      <td>0.004931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.196207</td>\n",
       "      <td>0.008335</td>\n",
       "      <td>0.114586</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.747750</td>\n",
       "      <td>0.854856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627850</td>\n",
       "      <td>0.198822</td>\n",
       "      <td>21</td>\n",
       "      <td>0.985870</td>\n",
       "      <td>0.982107</td>\n",
       "      <td>0.979956</td>\n",
       "      <td>0.986754</td>\n",
       "      <td>0.980199</td>\n",
       "      <td>0.982977</td>\n",
       "      <td>0.002837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.230545</td>\n",
       "      <td>0.010746</td>\n",
       "      <td>0.114597</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.5, 'min_samples_leaf': 10, ...</td>\n",
       "      <td>0.765872</td>\n",
       "      <td>0.854409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625635</td>\n",
       "      <td>0.179315</td>\n",
       "      <td>22</td>\n",
       "      <td>0.879161</td>\n",
       "      <td>0.860072</td>\n",
       "      <td>0.827976</td>\n",
       "      <td>0.918968</td>\n",
       "      <td>0.871679</td>\n",
       "      <td>0.871571</td>\n",
       "      <td>0.029451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.174864</td>\n",
       "      <td>0.012145</td>\n",
       "      <td>0.113227</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.5, 'min_samples_leaf': 10, ...</td>\n",
       "      <td>0.750587</td>\n",
       "      <td>0.850987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625446</td>\n",
       "      <td>0.177384</td>\n",
       "      <td>23</td>\n",
       "      <td>0.876288</td>\n",
       "      <td>0.857154</td>\n",
       "      <td>0.832585</td>\n",
       "      <td>0.915342</td>\n",
       "      <td>0.870044</td>\n",
       "      <td>0.870282</td>\n",
       "      <td>0.027056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.230914</td>\n",
       "      <td>0.018446</td>\n",
       "      <td>0.123677</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 10, ...</td>\n",
       "      <td>0.758325</td>\n",
       "      <td>0.876644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625135</td>\n",
       "      <td>0.185534</td>\n",
       "      <td>24</td>\n",
       "      <td>0.879001</td>\n",
       "      <td>0.864058</td>\n",
       "      <td>0.845023</td>\n",
       "      <td>0.922338</td>\n",
       "      <td>0.876087</td>\n",
       "      <td>0.877301</td>\n",
       "      <td>0.025495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.075706</td>\n",
       "      <td>0.013237</td>\n",
       "      <td>0.126150</td>\n",
       "      <td>0.006950</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.6, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.749589</td>\n",
       "      <td>0.847120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623406</td>\n",
       "      <td>0.200007</td>\n",
       "      <td>25</td>\n",
       "      <td>0.918551</td>\n",
       "      <td>0.895834</td>\n",
       "      <td>0.882215</td>\n",
       "      <td>0.943226</td>\n",
       "      <td>0.908726</td>\n",
       "      <td>0.909710</td>\n",
       "      <td>0.020741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.196627</td>\n",
       "      <td>0.062898</td>\n",
       "      <td>0.119154</td>\n",
       "      <td>0.009361</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 10, ...</td>\n",
       "      <td>0.760109</td>\n",
       "      <td>0.870574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623396</td>\n",
       "      <td>0.195694</td>\n",
       "      <td>26</td>\n",
       "      <td>0.879726</td>\n",
       "      <td>0.866243</td>\n",
       "      <td>0.845834</td>\n",
       "      <td>0.919623</td>\n",
       "      <td>0.869683</td>\n",
       "      <td>0.876222</td>\n",
       "      <td>0.024338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.202093</td>\n",
       "      <td>0.030205</td>\n",
       "      <td>0.117918</td>\n",
       "      <td>0.008517</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.753818</td>\n",
       "      <td>0.869190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622839</td>\n",
       "      <td>0.187284</td>\n",
       "      <td>27</td>\n",
       "      <td>0.923924</td>\n",
       "      <td>0.911253</td>\n",
       "      <td>0.903611</td>\n",
       "      <td>0.950099</td>\n",
       "      <td>0.922460</td>\n",
       "      <td>0.922269</td>\n",
       "      <td>0.015791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.269931</td>\n",
       "      <td>0.055022</td>\n",
       "      <td>0.113199</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.6, 'min_samples_leaf': 10, ...</td>\n",
       "      <td>0.751888</td>\n",
       "      <td>0.867510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622623</td>\n",
       "      <td>0.186646</td>\n",
       "      <td>28</td>\n",
       "      <td>0.880092</td>\n",
       "      <td>0.859373</td>\n",
       "      <td>0.840972</td>\n",
       "      <td>0.923987</td>\n",
       "      <td>0.875761</td>\n",
       "      <td>0.876037</td>\n",
       "      <td>0.027651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.203022</td>\n",
       "      <td>0.022295</td>\n",
       "      <td>0.120130</td>\n",
       "      <td>0.007176</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.4, 'min_samples_leaf': 5, '...</td>\n",
       "      <td>0.760960</td>\n",
       "      <td>0.857374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621949</td>\n",
       "      <td>0.190158</td>\n",
       "      <td>29</td>\n",
       "      <td>0.924022</td>\n",
       "      <td>0.904163</td>\n",
       "      <td>0.893679</td>\n",
       "      <td>0.944682</td>\n",
       "      <td>0.910075</td>\n",
       "      <td>0.915324</td>\n",
       "      <td>0.017653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.237170</td>\n",
       "      <td>0.041940</td>\n",
       "      <td>0.124239</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.4, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.753572</td>\n",
       "      <td>0.872772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620291</td>\n",
       "      <td>0.258275</td>\n",
       "      <td>30</td>\n",
       "      <td>0.984264</td>\n",
       "      <td>0.982611</td>\n",
       "      <td>0.979618</td>\n",
       "      <td>0.986173</td>\n",
       "      <td>0.984670</td>\n",
       "      <td>0.983467</td>\n",
       "      <td>0.002234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.068770</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>0.126971</td>\n",
       "      <td>0.006543</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.3, 'min_samples_leaf': 10, ...</td>\n",
       "      <td>0.717652</td>\n",
       "      <td>0.726116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465864</td>\n",
       "      <td>0.236407</td>\n",
       "      <td>76</td>\n",
       "      <td>0.828205</td>\n",
       "      <td>0.805481</td>\n",
       "      <td>0.768986</td>\n",
       "      <td>0.855292</td>\n",
       "      <td>0.818992</td>\n",
       "      <td>0.815391</td>\n",
       "      <td>0.028358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.067808</td>\n",
       "      <td>0.010980</td>\n",
       "      <td>0.124360</td>\n",
       "      <td>0.008228</td>\n",
       "      <td>0.4</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.4, 'min_samples_leaf': 25, ...</td>\n",
       "      <td>0.624734</td>\n",
       "      <td>0.749282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439899</td>\n",
       "      <td>0.251660</td>\n",
       "      <td>77</td>\n",
       "      <td>0.757199</td>\n",
       "      <td>0.738547</td>\n",
       "      <td>0.705846</td>\n",
       "      <td>0.811861</td>\n",
       "      <td>0.756412</td>\n",
       "      <td>0.753973</td>\n",
       "      <td>0.034414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.180930</td>\n",
       "      <td>0.033875</td>\n",
       "      <td>0.125031</td>\n",
       "      <td>0.007291</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 10, ...</td>\n",
       "      <td>0.650407</td>\n",
       "      <td>0.714605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.431585</td>\n",
       "      <td>0.249814</td>\n",
       "      <td>78</td>\n",
       "      <td>0.819102</td>\n",
       "      <td>0.783502</td>\n",
       "      <td>0.765602</td>\n",
       "      <td>0.850413</td>\n",
       "      <td>0.789898</td>\n",
       "      <td>0.801703</td>\n",
       "      <td>0.029831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.218368</td>\n",
       "      <td>0.010467</td>\n",
       "      <td>0.113657</td>\n",
       "      <td>0.006036</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.3, 'min_samples_leaf': 25, ...</td>\n",
       "      <td>0.592277</td>\n",
       "      <td>0.671321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417997</td>\n",
       "      <td>0.180965</td>\n",
       "      <td>79</td>\n",
       "      <td>0.737118</td>\n",
       "      <td>0.712036</td>\n",
       "      <td>0.671091</td>\n",
       "      <td>0.792313</td>\n",
       "      <td>0.717571</td>\n",
       "      <td>0.726026</td>\n",
       "      <td>0.039502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.065980</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>0.118202</td>\n",
       "      <td>0.002722</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.3, 'min_samples_leaf': 25, ...</td>\n",
       "      <td>0.603330</td>\n",
       "      <td>0.660520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413995</td>\n",
       "      <td>0.247753</td>\n",
       "      <td>80</td>\n",
       "      <td>0.761561</td>\n",
       "      <td>0.706936</td>\n",
       "      <td>0.685565</td>\n",
       "      <td>0.761096</td>\n",
       "      <td>0.644721</td>\n",
       "      <td>0.711976</td>\n",
       "      <td>0.044984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.837242</td>\n",
       "      <td>1.532662</td>\n",
       "      <td>0.137253</td>\n",
       "      <td>0.047355</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.664692</td>\n",
       "      <td>0.714682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374030</td>\n",
       "      <td>0.490833</td>\n",
       "      <td>81</td>\n",
       "      <td>0.975065</td>\n",
       "      <td>0.967663</td>\n",
       "      <td>0.956488</td>\n",
       "      <td>0.979908</td>\n",
       "      <td>0.969051</td>\n",
       "      <td>0.969635</td>\n",
       "      <td>0.007901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.064458</td>\n",
       "      <td>0.017116</td>\n",
       "      <td>0.120058</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>0.4</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.4, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.702919</td>\n",
       "      <td>0.664413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372677</td>\n",
       "      <td>0.265510</td>\n",
       "      <td>82</td>\n",
       "      <td>0.683315</td>\n",
       "      <td>0.660832</td>\n",
       "      <td>0.538741</td>\n",
       "      <td>0.727928</td>\n",
       "      <td>0.667792</td>\n",
       "      <td>0.655722</td>\n",
       "      <td>0.062979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.138356</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>0.118105</td>\n",
       "      <td>0.010832</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 25, ...</td>\n",
       "      <td>0.497843</td>\n",
       "      <td>0.668642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348925</td>\n",
       "      <td>0.220361</td>\n",
       "      <td>83</td>\n",
       "      <td>0.678063</td>\n",
       "      <td>0.688901</td>\n",
       "      <td>0.634359</td>\n",
       "      <td>0.767409</td>\n",
       "      <td>0.635591</td>\n",
       "      <td>0.680865</td>\n",
       "      <td>0.048528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.219666</td>\n",
       "      <td>0.024318</td>\n",
       "      <td>0.112592</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.5, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.586777</td>\n",
       "      <td>0.679995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346785</td>\n",
       "      <td>0.261563</td>\n",
       "      <td>84</td>\n",
       "      <td>0.667822</td>\n",
       "      <td>0.649660</td>\n",
       "      <td>0.591151</td>\n",
       "      <td>0.723122</td>\n",
       "      <td>0.665764</td>\n",
       "      <td>0.659504</td>\n",
       "      <td>0.042248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.221711</td>\n",
       "      <td>0.013860</td>\n",
       "      <td>0.114709</td>\n",
       "      <td>0.006109</td>\n",
       "      <td>0.4</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.4, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.637893</td>\n",
       "      <td>0.658887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343553</td>\n",
       "      <td>0.269445</td>\n",
       "      <td>85</td>\n",
       "      <td>0.671212</td>\n",
       "      <td>0.639416</td>\n",
       "      <td>0.588843</td>\n",
       "      <td>0.716637</td>\n",
       "      <td>0.648971</td>\n",
       "      <td>0.653016</td>\n",
       "      <td>0.041709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.217528</td>\n",
       "      <td>0.020465</td>\n",
       "      <td>0.119408</td>\n",
       "      <td>0.009654</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.6, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.611366</td>\n",
       "      <td>0.678732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340464</td>\n",
       "      <td>0.282816</td>\n",
       "      <td>86</td>\n",
       "      <td>0.671158</td>\n",
       "      <td>0.643752</td>\n",
       "      <td>0.595079</td>\n",
       "      <td>0.739056</td>\n",
       "      <td>0.660713</td>\n",
       "      <td>0.661951</td>\n",
       "      <td>0.046550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.188863</td>\n",
       "      <td>0.016729</td>\n",
       "      <td>0.121123</td>\n",
       "      <td>0.007024</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.592252</td>\n",
       "      <td>0.708058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338495</td>\n",
       "      <td>0.306622</td>\n",
       "      <td>87</td>\n",
       "      <td>0.681153</td>\n",
       "      <td>0.674112</td>\n",
       "      <td>0.600622</td>\n",
       "      <td>0.746670</td>\n",
       "      <td>0.681177</td>\n",
       "      <td>0.676747</td>\n",
       "      <td>0.046325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.065679</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>0.116910</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.5, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.729027</td>\n",
       "      <td>0.635089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334774</td>\n",
       "      <td>0.321365</td>\n",
       "      <td>88</td>\n",
       "      <td>0.646764</td>\n",
       "      <td>0.628027</td>\n",
       "      <td>0.582609</td>\n",
       "      <td>0.698872</td>\n",
       "      <td>0.650022</td>\n",
       "      <td>0.641259</td>\n",
       "      <td>0.037526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.174739</td>\n",
       "      <td>0.008454</td>\n",
       "      <td>0.112439</td>\n",
       "      <td>0.003324</td>\n",
       "      <td>0.4</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.4, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.626225</td>\n",
       "      <td>0.632104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334194</td>\n",
       "      <td>0.259274</td>\n",
       "      <td>89</td>\n",
       "      <td>0.663693</td>\n",
       "      <td>0.624042</td>\n",
       "      <td>0.593066</td>\n",
       "      <td>0.728428</td>\n",
       "      <td>0.651106</td>\n",
       "      <td>0.652067</td>\n",
       "      <td>0.045240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.186988</td>\n",
       "      <td>0.055639</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.005794</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.5, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.619492</td>\n",
       "      <td>0.678787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332553</td>\n",
       "      <td>0.296597</td>\n",
       "      <td>90</td>\n",
       "      <td>0.665774</td>\n",
       "      <td>0.653938</td>\n",
       "      <td>0.582855</td>\n",
       "      <td>0.755382</td>\n",
       "      <td>0.659040</td>\n",
       "      <td>0.663398</td>\n",
       "      <td>0.054886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.202951</td>\n",
       "      <td>0.031702</td>\n",
       "      <td>0.117458</td>\n",
       "      <td>0.003889</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.550153</td>\n",
       "      <td>0.700312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332001</td>\n",
       "      <td>0.289881</td>\n",
       "      <td>91</td>\n",
       "      <td>0.679832</td>\n",
       "      <td>0.670667</td>\n",
       "      <td>0.603998</td>\n",
       "      <td>0.736006</td>\n",
       "      <td>0.670026</td>\n",
       "      <td>0.672106</td>\n",
       "      <td>0.041924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.211631</td>\n",
       "      <td>0.009279</td>\n",
       "      <td>0.114067</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.622963</td>\n",
       "      <td>0.699486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331433</td>\n",
       "      <td>0.323017</td>\n",
       "      <td>92</td>\n",
       "      <td>0.685834</td>\n",
       "      <td>0.664311</td>\n",
       "      <td>0.608311</td>\n",
       "      <td>0.739096</td>\n",
       "      <td>0.671836</td>\n",
       "      <td>0.673877</td>\n",
       "      <td>0.041931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.182355</td>\n",
       "      <td>0.015353</td>\n",
       "      <td>0.121190</td>\n",
       "      <td>0.008859</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.6, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.516183</td>\n",
       "      <td>0.688823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327565</td>\n",
       "      <td>0.256795</td>\n",
       "      <td>93</td>\n",
       "      <td>0.657547</td>\n",
       "      <td>0.656210</td>\n",
       "      <td>0.595956</td>\n",
       "      <td>0.740548</td>\n",
       "      <td>0.668125</td>\n",
       "      <td>0.663677</td>\n",
       "      <td>0.046062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.186424</td>\n",
       "      <td>0.030565</td>\n",
       "      <td>0.113383</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 25, ...</td>\n",
       "      <td>0.545118</td>\n",
       "      <td>0.611298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326835</td>\n",
       "      <td>0.223461</td>\n",
       "      <td>94</td>\n",
       "      <td>0.685961</td>\n",
       "      <td>0.666525</td>\n",
       "      <td>0.605300</td>\n",
       "      <td>0.761327</td>\n",
       "      <td>0.659035</td>\n",
       "      <td>0.675630</td>\n",
       "      <td>0.050508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.286134</td>\n",
       "      <td>0.087012</td>\n",
       "      <td>0.115346</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.564734</td>\n",
       "      <td>0.704117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319167</td>\n",
       "      <td>0.315888</td>\n",
       "      <td>95</td>\n",
       "      <td>0.688908</td>\n",
       "      <td>0.659345</td>\n",
       "      <td>0.609321</td>\n",
       "      <td>0.740094</td>\n",
       "      <td>0.672415</td>\n",
       "      <td>0.674016</td>\n",
       "      <td>0.042406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.065130</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0.115423</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.8, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.580629</td>\n",
       "      <td>0.656539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314428</td>\n",
       "      <td>0.329626</td>\n",
       "      <td>96</td>\n",
       "      <td>0.673440</td>\n",
       "      <td>0.629222</td>\n",
       "      <td>0.609394</td>\n",
       "      <td>0.737399</td>\n",
       "      <td>0.659031</td>\n",
       "      <td>0.661697</td>\n",
       "      <td>0.043968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.064687</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.121473</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.6, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.516041</td>\n",
       "      <td>0.686233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291533</td>\n",
       "      <td>0.328808</td>\n",
       "      <td>97</td>\n",
       "      <td>0.670178</td>\n",
       "      <td>0.649296</td>\n",
       "      <td>0.594106</td>\n",
       "      <td>0.696793</td>\n",
       "      <td>0.650977</td>\n",
       "      <td>0.652270</td>\n",
       "      <td>0.033754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.073185</td>\n",
       "      <td>0.026278</td>\n",
       "      <td>0.120960</td>\n",
       "      <td>0.009316</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.7, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.545262</td>\n",
       "      <td>0.695668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276567</td>\n",
       "      <td>0.352102</td>\n",
       "      <td>98</td>\n",
       "      <td>0.667223</td>\n",
       "      <td>0.666032</td>\n",
       "      <td>0.596484</td>\n",
       "      <td>0.728867</td>\n",
       "      <td>0.656995</td>\n",
       "      <td>0.663120</td>\n",
       "      <td>0.042014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.063172</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>0.115274</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 25, ...</td>\n",
       "      <td>0.502506</td>\n",
       "      <td>0.670466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263809</td>\n",
       "      <td>0.309177</td>\n",
       "      <td>99</td>\n",
       "      <td>0.686664</td>\n",
       "      <td>0.678674</td>\n",
       "      <td>0.545963</td>\n",
       "      <td>0.749778</td>\n",
       "      <td>0.638056</td>\n",
       "      <td>0.659827</td>\n",
       "      <td>0.067239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.293850</td>\n",
       "      <td>0.050967</td>\n",
       "      <td>0.117440</td>\n",
       "      <td>0.006077</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.3, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.536424</td>\n",
       "      <td>0.551428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249258</td>\n",
       "      <td>0.271703</td>\n",
       "      <td>100</td>\n",
       "      <td>0.624974</td>\n",
       "      <td>0.589398</td>\n",
       "      <td>0.530887</td>\n",
       "      <td>0.667675</td>\n",
       "      <td>0.562923</td>\n",
       "      <td>0.595171</td>\n",
       "      <td>0.047646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.229686</td>\n",
       "      <td>0.037299</td>\n",
       "      <td>0.116645</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.3, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.559704</td>\n",
       "      <td>0.509066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247080</td>\n",
       "      <td>0.259738</td>\n",
       "      <td>101</td>\n",
       "      <td>0.635015</td>\n",
       "      <td>0.568703</td>\n",
       "      <td>0.543459</td>\n",
       "      <td>0.669988</td>\n",
       "      <td>0.589701</td>\n",
       "      <td>0.601373</td>\n",
       "      <td>0.045601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.089847</td>\n",
       "      <td>0.009647</td>\n",
       "      <td>0.125597</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.3, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.532917</td>\n",
       "      <td>0.557677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231508</td>\n",
       "      <td>0.272583</td>\n",
       "      <td>102</td>\n",
       "      <td>0.602504</td>\n",
       "      <td>0.586683</td>\n",
       "      <td>0.519287</td>\n",
       "      <td>0.603996</td>\n",
       "      <td>0.599423</td>\n",
       "      <td>0.582379</td>\n",
       "      <td>0.032131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.065988</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.120357</td>\n",
       "      <td>0.003890</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.377553</td>\n",
       "      <td>0.456916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187798</td>\n",
       "      <td>0.229433</td>\n",
       "      <td>103</td>\n",
       "      <td>0.538313</td>\n",
       "      <td>0.515577</td>\n",
       "      <td>0.515177</td>\n",
       "      <td>0.631410</td>\n",
       "      <td>0.596423</td>\n",
       "      <td>0.559380</td>\n",
       "      <td>0.046641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.151941</td>\n",
       "      <td>0.004791</td>\n",
       "      <td>0.125338</td>\n",
       "      <td>0.009015</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.381621</td>\n",
       "      <td>0.489266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152992</td>\n",
       "      <td>0.283435</td>\n",
       "      <td>104</td>\n",
       "      <td>0.550696</td>\n",
       "      <td>0.524976</td>\n",
       "      <td>0.484821</td>\n",
       "      <td>0.648215</td>\n",
       "      <td>0.501515</td>\n",
       "      <td>0.542045</td>\n",
       "      <td>0.057542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.195693</td>\n",
       "      <td>0.014112</td>\n",
       "      <td>0.120310</td>\n",
       "      <td>0.006972</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 0.2, 'min_samples_leaf': 50, ...</td>\n",
       "      <td>0.371903</td>\n",
       "      <td>0.514043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128670</td>\n",
       "      <td>0.308399</td>\n",
       "      <td>105</td>\n",
       "      <td>0.552130</td>\n",
       "      <td>0.556581</td>\n",
       "      <td>0.485621</td>\n",
       "      <td>0.620239</td>\n",
       "      <td>0.477319</td>\n",
       "      <td>0.538378</td>\n",
       "      <td>0.052409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "33        0.075773      0.007419         0.127579        0.012758   \n",
       "46        0.204946      0.014164         0.120121        0.007557   \n",
       "47        0.254692      0.012598         0.115289        0.006896   \n",
       "49        0.208347      0.022103         0.115135        0.005718   \n",
       "62        0.309309      0.045359         0.117833        0.007485   \n",
       "90        0.067919      0.005169         0.123010        0.004263   \n",
       "65        0.242313      0.006617         0.115801        0.005669   \n",
       "76        0.240963      0.031615         0.122963        0.009887   \n",
       "61        0.261204      0.030451         0.116824        0.005366   \n",
       "77        0.283978      0.024461         0.122646        0.008844   \n",
       "45        0.070690      0.005243         0.121437        0.005511   \n",
       "32        0.265492      0.039781         0.114958        0.002603   \n",
       "92        0.286556      0.028571         0.113007        0.002647   \n",
       "95        0.246049      0.016695         0.112065        0.001716   \n",
       "50        0.263239      0.030875         0.126368        0.003090   \n",
       "35        0.222796      0.010784         0.114300        0.002010   \n",
       "80        0.284329      0.031211         0.114525        0.002063   \n",
       "60        0.073307      0.021726         0.113977        0.004269   \n",
       "64        0.202776      0.006435         0.114657        0.001541   \n",
       "75        0.075326      0.009287         0.129144        0.007208   \n",
       "91        0.196207      0.008335         0.114586        0.000845   \n",
       "53        0.230545      0.010746         0.114597        0.002071   \n",
       "52        0.174864      0.012145         0.113227        0.002428   \n",
       "98        0.230914      0.018446         0.123677        0.006815   \n",
       "63        0.075706      0.013237         0.126150        0.006950   \n",
       "97        0.196627      0.062898         0.119154        0.009361   \n",
       "79        0.202093      0.030205         0.117918        0.008517   \n",
       "68        0.269931      0.055022         0.113199        0.001820   \n",
       "34        0.203022      0.022295         0.120130        0.007176   \n",
       "31        0.237170      0.041940         0.124239        0.002671   \n",
       "..             ...           ...              ...             ...   \n",
       "21        0.068770      0.003528         0.126971        0.006543   \n",
       "39        0.067808      0.010980         0.124360        0.008228   \n",
       "7         0.180930      0.033875         0.125031        0.007291   \n",
       "26        0.218368      0.010467         0.113657        0.006036   \n",
       "24        0.065980      0.003493         0.118202        0.002722   \n",
       "0         0.837242      1.532662         0.137253        0.047355   \n",
       "42        0.064458      0.017116         0.120058        0.004076   \n",
       "10        0.138356      0.030100         0.118105        0.010832   \n",
       "59        0.219666      0.024318         0.112592        0.003607   \n",
       "44        0.221711      0.013860         0.114709        0.006109   \n",
       "74        0.217528      0.020465         0.119408        0.009654   \n",
       "88        0.188863      0.016729         0.121123        0.007024   \n",
       "57        0.065679      0.003506         0.116910        0.003353   \n",
       "43        0.174739      0.008454         0.112439        0.003324   \n",
       "58        0.186988      0.055639         0.117095        0.005794   \n",
       "103       0.202951      0.031702         0.117458        0.003889   \n",
       "89        0.211631      0.009279         0.114067        0.001858   \n",
       "73        0.182355      0.015353         0.121190        0.008859   \n",
       "11        0.186424      0.030565         0.113383        0.002830   \n",
       "104       0.286134      0.087012         0.115346        0.005452   \n",
       "102       0.065130      0.003085         0.115423        0.002576   \n",
       "72        0.064687      0.013514         0.121473        0.004120   \n",
       "87        0.073185      0.026278         0.120960        0.009316   \n",
       "9         0.063172      0.001363         0.115274        0.001780   \n",
       "29        0.293850      0.050967         0.117440        0.006077   \n",
       "28        0.229686      0.037299         0.116645        0.003165   \n",
       "27        0.089847      0.009647         0.125597        0.006900   \n",
       "12        0.065988      0.001161         0.120357        0.003890   \n",
       "13        0.151941      0.004791         0.125338        0.009015   \n",
       "14        0.195693      0.014112         0.120310        0.006972   \n",
       "\n",
       "    param_max_features param_min_samples_leaf param_n_estimators  \\\n",
       "33                 0.4                      5                 10   \n",
       "46                 0.5                      1                 50   \n",
       "47                 0.5                      1                100   \n",
       "49                 0.5                      5                 50   \n",
       "62                 0.6                      1                100   \n",
       "90                 0.8                      1                 10   \n",
       "65                 0.6                      5                100   \n",
       "76                 0.7                      1                 50   \n",
       "61                 0.6                      1                 50   \n",
       "77                 0.7                      1                100   \n",
       "45                 0.5                      1                 10   \n",
       "32                 0.4                      1                100   \n",
       "92                 0.8                      1                100   \n",
       "95                 0.8                      5                100   \n",
       "50                 0.5                      5                100   \n",
       "35                 0.4                      5                100   \n",
       "80                 0.7                      5                100   \n",
       "60                 0.6                      1                 10   \n",
       "64                 0.6                      5                 50   \n",
       "75                 0.7                      1                 10   \n",
       "91                 0.8                      1                 50   \n",
       "53                 0.5                     10                100   \n",
       "52                 0.5                     10                 50   \n",
       "98                 0.8                     10                100   \n",
       "63                 0.6                      5                 10   \n",
       "97                 0.8                     10                 50   \n",
       "79                 0.7                      5                 50   \n",
       "68                 0.6                     10                100   \n",
       "34                 0.4                      5                 50   \n",
       "31                 0.4                      1                 50   \n",
       "..                 ...                    ...                ...   \n",
       "21                 0.3                     10                 10   \n",
       "39                 0.4                     25                 10   \n",
       "7                  0.2                     10                 50   \n",
       "26                 0.3                     25                100   \n",
       "24                 0.3                     25                 10   \n",
       "0                  0.2                      1                 10   \n",
       "42                 0.4                     50                 10   \n",
       "10                 0.2                     25                 50   \n",
       "59                 0.5                     50                100   \n",
       "44                 0.4                     50                100   \n",
       "74                 0.6                     50                100   \n",
       "88                 0.7                     50                 50   \n",
       "57                 0.5                     50                 10   \n",
       "43                 0.4                     50                 50   \n",
       "58                 0.5                     50                 50   \n",
       "103                0.8                     50                 50   \n",
       "89                 0.7                     50                100   \n",
       "73                 0.6                     50                 50   \n",
       "11                 0.2                     25                100   \n",
       "104                0.8                     50                100   \n",
       "102                0.8                     50                 10   \n",
       "72                 0.6                     50                 10   \n",
       "87                 0.7                     50                 10   \n",
       "9                  0.2                     25                 10   \n",
       "29                 0.3                     50                100   \n",
       "28                 0.3                     50                 50   \n",
       "27                 0.3                     50                 10   \n",
       "12                 0.2                     50                 10   \n",
       "13                 0.2                     50                 50   \n",
       "14                 0.2                     50                100   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "33   {'max_features': 0.4, 'min_samples_leaf': 5, '...           0.759879   \n",
       "46   {'max_features': 0.5, 'min_samples_leaf': 1, '...           0.755386   \n",
       "47   {'max_features': 0.5, 'min_samples_leaf': 1, '...           0.763938   \n",
       "49   {'max_features': 0.5, 'min_samples_leaf': 5, '...           0.752754   \n",
       "62   {'max_features': 0.6, 'min_samples_leaf': 1, '...           0.769179   \n",
       "90   {'max_features': 0.8, 'min_samples_leaf': 1, '...           0.756370   \n",
       "65   {'max_features': 0.6, 'min_samples_leaf': 5, '...           0.759523   \n",
       "76   {'max_features': 0.7, 'min_samples_leaf': 1, '...           0.758610   \n",
       "61   {'max_features': 0.6, 'min_samples_leaf': 1, '...           0.772119   \n",
       "77   {'max_features': 0.7, 'min_samples_leaf': 1, '...           0.766007   \n",
       "45   {'max_features': 0.5, 'min_samples_leaf': 1, '...           0.750575   \n",
       "32   {'max_features': 0.4, 'min_samples_leaf': 1, '...           0.765890   \n",
       "92   {'max_features': 0.8, 'min_samples_leaf': 1, '...           0.762136   \n",
       "95   {'max_features': 0.8, 'min_samples_leaf': 5, '...           0.761560   \n",
       "50   {'max_features': 0.5, 'min_samples_leaf': 5, '...           0.753900   \n",
       "35   {'max_features': 0.4, 'min_samples_leaf': 5, '...           0.750279   \n",
       "80   {'max_features': 0.7, 'min_samples_leaf': 5, '...           0.758558   \n",
       "60   {'max_features': 0.6, 'min_samples_leaf': 1, '...           0.705933   \n",
       "64   {'max_features': 0.6, 'min_samples_leaf': 5, '...           0.768845   \n",
       "75   {'max_features': 0.7, 'min_samples_leaf': 1, '...           0.763077   \n",
       "91   {'max_features': 0.8, 'min_samples_leaf': 1, '...           0.747750   \n",
       "53   {'max_features': 0.5, 'min_samples_leaf': 10, ...           0.765872   \n",
       "52   {'max_features': 0.5, 'min_samples_leaf': 10, ...           0.750587   \n",
       "98   {'max_features': 0.8, 'min_samples_leaf': 10, ...           0.758325   \n",
       "63   {'max_features': 0.6, 'min_samples_leaf': 5, '...           0.749589   \n",
       "97   {'max_features': 0.8, 'min_samples_leaf': 10, ...           0.760109   \n",
       "79   {'max_features': 0.7, 'min_samples_leaf': 5, '...           0.753818   \n",
       "68   {'max_features': 0.6, 'min_samples_leaf': 10, ...           0.751888   \n",
       "34   {'max_features': 0.4, 'min_samples_leaf': 5, '...           0.760960   \n",
       "31   {'max_features': 0.4, 'min_samples_leaf': 1, '...           0.753572   \n",
       "..                                                 ...                ...   \n",
       "21   {'max_features': 0.3, 'min_samples_leaf': 10, ...           0.717652   \n",
       "39   {'max_features': 0.4, 'min_samples_leaf': 25, ...           0.624734   \n",
       "7    {'max_features': 0.2, 'min_samples_leaf': 10, ...           0.650407   \n",
       "26   {'max_features': 0.3, 'min_samples_leaf': 25, ...           0.592277   \n",
       "24   {'max_features': 0.3, 'min_samples_leaf': 25, ...           0.603330   \n",
       "0    {'max_features': 0.2, 'min_samples_leaf': 1, '...           0.664692   \n",
       "42   {'max_features': 0.4, 'min_samples_leaf': 50, ...           0.702919   \n",
       "10   {'max_features': 0.2, 'min_samples_leaf': 25, ...           0.497843   \n",
       "59   {'max_features': 0.5, 'min_samples_leaf': 50, ...           0.586777   \n",
       "44   {'max_features': 0.4, 'min_samples_leaf': 50, ...           0.637893   \n",
       "74   {'max_features': 0.6, 'min_samples_leaf': 50, ...           0.611366   \n",
       "88   {'max_features': 0.7, 'min_samples_leaf': 50, ...           0.592252   \n",
       "57   {'max_features': 0.5, 'min_samples_leaf': 50, ...           0.729027   \n",
       "43   {'max_features': 0.4, 'min_samples_leaf': 50, ...           0.626225   \n",
       "58   {'max_features': 0.5, 'min_samples_leaf': 50, ...           0.619492   \n",
       "103  {'max_features': 0.8, 'min_samples_leaf': 50, ...           0.550153   \n",
       "89   {'max_features': 0.7, 'min_samples_leaf': 50, ...           0.622963   \n",
       "73   {'max_features': 0.6, 'min_samples_leaf': 50, ...           0.516183   \n",
       "11   {'max_features': 0.2, 'min_samples_leaf': 25, ...           0.545118   \n",
       "104  {'max_features': 0.8, 'min_samples_leaf': 50, ...           0.564734   \n",
       "102  {'max_features': 0.8, 'min_samples_leaf': 50, ...           0.580629   \n",
       "72   {'max_features': 0.6, 'min_samples_leaf': 50, ...           0.516041   \n",
       "87   {'max_features': 0.7, 'min_samples_leaf': 50, ...           0.545262   \n",
       "9    {'max_features': 0.2, 'min_samples_leaf': 25, ...           0.502506   \n",
       "29   {'max_features': 0.3, 'min_samples_leaf': 50, ...           0.536424   \n",
       "28   {'max_features': 0.3, 'min_samples_leaf': 50, ...           0.559704   \n",
       "27   {'max_features': 0.3, 'min_samples_leaf': 50, ...           0.532917   \n",
       "12   {'max_features': 0.2, 'min_samples_leaf': 50, ...           0.377553   \n",
       "13   {'max_features': 0.2, 'min_samples_leaf': 50, ...           0.381621   \n",
       "14   {'max_features': 0.2, 'min_samples_leaf': 50, ...           0.371903   \n",
       "\n",
       "     split1_test_score       ...         mean_test_score  std_test_score  \\\n",
       "33            0.844738       ...                0.673682        0.153816   \n",
       "46            0.863149       ...                0.666336        0.184254   \n",
       "47            0.860562       ...                0.659012        0.180616   \n",
       "49            0.856948       ...                0.658619        0.155379   \n",
       "62            0.866195       ...                0.658172        0.185553   \n",
       "90            0.861020       ...                0.658000        0.161479   \n",
       "65            0.869465       ...                0.657166        0.174786   \n",
       "76            0.862853       ...                0.656292        0.182968   \n",
       "61            0.865476       ...                0.653013        0.177449   \n",
       "77            0.867278       ...                0.650958        0.185087   \n",
       "45            0.827131       ...                0.646574        0.161650   \n",
       "32            0.855205       ...                0.646406        0.192223   \n",
       "92            0.865524       ...                0.645210        0.187350   \n",
       "95            0.871962       ...                0.643844        0.177431   \n",
       "50            0.854616       ...                0.641711        0.179646   \n",
       "35            0.850314       ...                0.640562        0.178726   \n",
       "80            0.865411       ...                0.639242        0.179629   \n",
       "60            0.869563       ...                0.637882        0.172156   \n",
       "64            0.868330       ...                0.635577        0.208824   \n",
       "75            0.842206       ...                0.628259        0.228532   \n",
       "91            0.854856       ...                0.627850        0.198822   \n",
       "53            0.854409       ...                0.625635        0.179315   \n",
       "52            0.850987       ...                0.625446        0.177384   \n",
       "98            0.876644       ...                0.625135        0.185534   \n",
       "63            0.847120       ...                0.623406        0.200007   \n",
       "97            0.870574       ...                0.623396        0.195694   \n",
       "79            0.869190       ...                0.622839        0.187284   \n",
       "68            0.867510       ...                0.622623        0.186646   \n",
       "34            0.857374       ...                0.621949        0.190158   \n",
       "31            0.872772       ...                0.620291        0.258275   \n",
       "..                 ...       ...                     ...             ...   \n",
       "21            0.726116       ...                0.465864        0.236407   \n",
       "39            0.749282       ...                0.439899        0.251660   \n",
       "7             0.714605       ...                0.431585        0.249814   \n",
       "26            0.671321       ...                0.417997        0.180965   \n",
       "24            0.660520       ...                0.413995        0.247753   \n",
       "0             0.714682       ...                0.374030        0.490833   \n",
       "42            0.664413       ...                0.372677        0.265510   \n",
       "10            0.668642       ...                0.348925        0.220361   \n",
       "59            0.679995       ...                0.346785        0.261563   \n",
       "44            0.658887       ...                0.343553        0.269445   \n",
       "74            0.678732       ...                0.340464        0.282816   \n",
       "88            0.708058       ...                0.338495        0.306622   \n",
       "57            0.635089       ...                0.334774        0.321365   \n",
       "43            0.632104       ...                0.334194        0.259274   \n",
       "58            0.678787       ...                0.332553        0.296597   \n",
       "103           0.700312       ...                0.332001        0.289881   \n",
       "89            0.699486       ...                0.331433        0.323017   \n",
       "73            0.688823       ...                0.327565        0.256795   \n",
       "11            0.611298       ...                0.326835        0.223461   \n",
       "104           0.704117       ...                0.319167        0.315888   \n",
       "102           0.656539       ...                0.314428        0.329626   \n",
       "72            0.686233       ...                0.291533        0.328808   \n",
       "87            0.695668       ...                0.276567        0.352102   \n",
       "9             0.670466       ...                0.263809        0.309177   \n",
       "29            0.551428       ...                0.249258        0.271703   \n",
       "28            0.509066       ...                0.247080        0.259738   \n",
       "27            0.557677       ...                0.231508        0.272583   \n",
       "12            0.456916       ...                0.187798        0.229433   \n",
       "13            0.489266       ...                0.152992        0.283435   \n",
       "14            0.514043       ...                0.128670        0.308399   \n",
       "\n",
       "     rank_test_score  split0_train_score  split1_train_score  \\\n",
       "33                 1            0.911802            0.909605   \n",
       "46                 2            0.981631            0.978837   \n",
       "47                 3            0.984083            0.983177   \n",
       "49                 4            0.918081            0.913259   \n",
       "62                 5            0.985434            0.980681   \n",
       "90                 6            0.979567            0.969565   \n",
       "65                 7            0.923424            0.916723   \n",
       "76                 8            0.982920            0.978571   \n",
       "61                 9            0.984468            0.983222   \n",
       "77                10            0.983763            0.982046   \n",
       "45                11            0.977724            0.972268   \n",
       "32                12            0.984459            0.982595   \n",
       "92                13            0.985415            0.980815   \n",
       "95                14            0.927406            0.915968   \n",
       "50                15            0.919956            0.912146   \n",
       "35                16            0.921521            0.906370   \n",
       "80                17            0.928356            0.915713   \n",
       "60                18            0.978501            0.976466   \n",
       "64                19            0.919234            0.910458   \n",
       "75                20            0.973284            0.973462   \n",
       "91                21            0.985870            0.982107   \n",
       "53                22            0.879161            0.860072   \n",
       "52                23            0.876288            0.857154   \n",
       "98                24            0.879001            0.864058   \n",
       "63                25            0.918551            0.895834   \n",
       "97                26            0.879726            0.866243   \n",
       "79                27            0.923924            0.911253   \n",
       "68                28            0.880092            0.859373   \n",
       "34                29            0.924022            0.904163   \n",
       "31                30            0.984264            0.982611   \n",
       "..               ...                 ...                 ...   \n",
       "21                76            0.828205            0.805481   \n",
       "39                77            0.757199            0.738547   \n",
       "7                 78            0.819102            0.783502   \n",
       "26                79            0.737118            0.712036   \n",
       "24                80            0.761561            0.706936   \n",
       "0                 81            0.975065            0.967663   \n",
       "42                82            0.683315            0.660832   \n",
       "10                83            0.678063            0.688901   \n",
       "59                84            0.667822            0.649660   \n",
       "44                85            0.671212            0.639416   \n",
       "74                86            0.671158            0.643752   \n",
       "88                87            0.681153            0.674112   \n",
       "57                88            0.646764            0.628027   \n",
       "43                89            0.663693            0.624042   \n",
       "58                90            0.665774            0.653938   \n",
       "103               91            0.679832            0.670667   \n",
       "89                92            0.685834            0.664311   \n",
       "73                93            0.657547            0.656210   \n",
       "11                94            0.685961            0.666525   \n",
       "104               95            0.688908            0.659345   \n",
       "102               96            0.673440            0.629222   \n",
       "72                97            0.670178            0.649296   \n",
       "87                98            0.667223            0.666032   \n",
       "9                 99            0.686664            0.678674   \n",
       "29               100            0.624974            0.589398   \n",
       "28               101            0.635015            0.568703   \n",
       "27               102            0.602504            0.586683   \n",
       "12               103            0.538313            0.515577   \n",
       "13               104            0.550696            0.524976   \n",
       "14               105            0.552130            0.556581   \n",
       "\n",
       "     split2_train_score  split3_train_score  split4_train_score  \\\n",
       "33             0.892976            0.936575            0.915583   \n",
       "46             0.979893            0.986491            0.980832   \n",
       "47             0.980008            0.987489            0.983567   \n",
       "49             0.898575            0.945113            0.908076   \n",
       "62             0.979287            0.987170            0.981918   \n",
       "90             0.971386            0.979468            0.974174   \n",
       "65             0.897542            0.949119            0.916960   \n",
       "76             0.978699            0.986612            0.983420   \n",
       "61             0.978606            0.986031            0.980642   \n",
       "77             0.978489            0.987217            0.983413   \n",
       "45             0.972245            0.980895            0.971573   \n",
       "32             0.979785            0.987855            0.982613   \n",
       "92             0.980638            0.986518            0.983668   \n",
       "95             0.909273            0.949805            0.920910   \n",
       "50             0.902405            0.948048            0.920031   \n",
       "35             0.893999            0.946436            0.917688   \n",
       "80             0.903464            0.951279            0.919976   \n",
       "60             0.975755            0.980182            0.976018   \n",
       "64             0.897865            0.948238            0.920949   \n",
       "75             0.967604            0.977620            0.982400   \n",
       "91             0.979956            0.986754            0.980199   \n",
       "53             0.827976            0.918968            0.871679   \n",
       "52             0.832585            0.915342            0.870044   \n",
       "98             0.845023            0.922338            0.876087   \n",
       "63             0.882215            0.943226            0.908726   \n",
       "97             0.845834            0.919623            0.869683   \n",
       "79             0.903611            0.950099            0.922460   \n",
       "68             0.840972            0.923987            0.875761   \n",
       "34             0.893679            0.944682            0.910075   \n",
       "31             0.979618            0.986173            0.984670   \n",
       "..                  ...                 ...                 ...   \n",
       "21             0.768986            0.855292            0.818992   \n",
       "39             0.705846            0.811861            0.756412   \n",
       "7              0.765602            0.850413            0.789898   \n",
       "26             0.671091            0.792313            0.717571   \n",
       "24             0.685565            0.761096            0.644721   \n",
       "0              0.956488            0.979908            0.969051   \n",
       "42             0.538741            0.727928            0.667792   \n",
       "10             0.634359            0.767409            0.635591   \n",
       "59             0.591151            0.723122            0.665764   \n",
       "44             0.588843            0.716637            0.648971   \n",
       "74             0.595079            0.739056            0.660713   \n",
       "88             0.600622            0.746670            0.681177   \n",
       "57             0.582609            0.698872            0.650022   \n",
       "43             0.593066            0.728428            0.651106   \n",
       "58             0.582855            0.755382            0.659040   \n",
       "103            0.603998            0.736006            0.670026   \n",
       "89             0.608311            0.739096            0.671836   \n",
       "73             0.595956            0.740548            0.668125   \n",
       "11             0.605300            0.761327            0.659035   \n",
       "104            0.609321            0.740094            0.672415   \n",
       "102            0.609394            0.737399            0.659031   \n",
       "72             0.594106            0.696793            0.650977   \n",
       "87             0.596484            0.728867            0.656995   \n",
       "9              0.545963            0.749778            0.638056   \n",
       "29             0.530887            0.667675            0.562923   \n",
       "28             0.543459            0.669988            0.589701   \n",
       "27             0.519287            0.603996            0.599423   \n",
       "12             0.515177            0.631410            0.596423   \n",
       "13             0.484821            0.648215            0.501515   \n",
       "14             0.485621            0.620239            0.477319   \n",
       "\n",
       "     mean_train_score  std_train_score  \n",
       "33           0.913308         0.013971  \n",
       "46           0.981537         0.002647  \n",
       "47           0.983665         0.002384  \n",
       "49           0.916621         0.015645  \n",
       "62           0.982898         0.002953  \n",
       "90           0.974832         0.004098  \n",
       "65           0.920753         0.016620  \n",
       "76           0.982045         0.003059  \n",
       "61           0.982594         0.002662  \n",
       "77           0.982986         0.002821  \n",
       "45           0.974941         0.003713  \n",
       "32           0.983461         0.002656  \n",
       "92           0.983411         0.002374  \n",
       "95           0.924672         0.013901  \n",
       "50           0.920517         0.015209  \n",
       "35           0.917203         0.017488  \n",
       "80           0.923757         0.015934  \n",
       "60           0.977385         0.001699  \n",
       "64           0.919349         0.016600  \n",
       "75           0.974874         0.004931  \n",
       "91           0.982977         0.002837  \n",
       "53           0.871571         0.029451  \n",
       "52           0.870282         0.027056  \n",
       "98           0.877301         0.025495  \n",
       "63           0.909710         0.020741  \n",
       "97           0.876222         0.024338  \n",
       "79           0.922269         0.015791  \n",
       "68           0.876037         0.027651  \n",
       "34           0.915324         0.017653  \n",
       "31           0.983467         0.002234  \n",
       "..                ...              ...  \n",
       "21           0.815391         0.028358  \n",
       "39           0.753973         0.034414  \n",
       "7            0.801703         0.029831  \n",
       "26           0.726026         0.039502  \n",
       "24           0.711976         0.044984  \n",
       "0            0.969635         0.007901  \n",
       "42           0.655722         0.062979  \n",
       "10           0.680865         0.048528  \n",
       "59           0.659504         0.042248  \n",
       "44           0.653016         0.041709  \n",
       "74           0.661951         0.046550  \n",
       "88           0.676747         0.046325  \n",
       "57           0.641259         0.037526  \n",
       "43           0.652067         0.045240  \n",
       "58           0.663398         0.054886  \n",
       "103          0.672106         0.041924  \n",
       "89           0.673877         0.041931  \n",
       "73           0.663677         0.046062  \n",
       "11           0.675630         0.050508  \n",
       "104          0.674016         0.042406  \n",
       "102          0.661697         0.043968  \n",
       "72           0.652270         0.033754  \n",
       "87           0.663120         0.042014  \n",
       "9            0.659827         0.067239  \n",
       "29           0.595171         0.047646  \n",
       "28           0.601373         0.045601  \n",
       "27           0.582379         0.032131  \n",
       "12           0.559380         0.046641  \n",
       "13           0.542045         0.057542  \n",
       "14           0.538378         0.052409  \n",
       "\n",
       "[105 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the rows by their highest test score\n",
    "grid_results.sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interpreting Grid Results:\n",
    "\n",
    " - Often very different model results will give very similar results, making it hard to tell how much of the best results were due to small chance\n",
    " - It's often useful to do data exploration on your cv results, to better understand what's driving them\n",
    " - Common things to look for:\n",
    "  - general patterns for what parameter value drives model results, vs. just looking at the highest ranking version\n",
    "  - useful cutoff points in parameters that give you similar to results, to best figure out how to reduce future fitting time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "param_n_estimators\n",
       "10     0.495344\n",
       "50     0.520959\n",
       "100    0.518378\n",
       "Name: mean_test_score, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how does the n_estimators argument effect accuracy?\n",
    "grid_results.groupby('param_n_estimators')['mean_test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "param_max_features\n",
       "0.2    0.382335\n",
       "0.3    0.471250\n",
       "0.4    0.531868\n",
       "0.5    0.552771\n",
       "0.6    0.544758\n",
       "0.7    0.539657\n",
       "0.8    0.545608\n",
       "Name: mean_test_score, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and max features?  -- notice how there's a sharp cutoff @ 0.4?  \n",
    "# this would be a sensible way to train your tree on future versions of your data if performance\n",
    "# is an issue\n",
    "grid_results.groupby('param_max_features')['mean_test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pipelines\n",
    "\n",
    " - separate module in Scikit Learn that allows you to chain together different processing functions\n",
    " - Useful for modularizing log-transforms, scaling, and other repetitive data processing methods\n",
    " - can be used with anything in scikit-learn that uses the transformer api\n",
    "  - ie, anything that uses the `transform`, and `fit_transform` methods\n",
    " - also makes it easier to build models off the same dataset without changing the original\n",
    "  - ie, use a scaler & function transformer w/ Lasso, so you can fit a random forest on the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# import scaler and the pipeline function\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# load both the scaler and lasso into the make_pipeline function\n",
    "pipe = make_pipeline(sc, lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns information about all of its individual sub-components\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jonat\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Jonat\\Anaconda\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit it like you normally would -- this will scale the data automatically\n",
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jonat\\Anaconda\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([29.50642173, 25.29187532, 30.77520395, 30.03821235, 29.43160435,\n",
       "       26.71405241, 23.68929336, 20.97261853, 13.50664087, 21.32119187,\n",
       "       21.11068147, 23.26305697, 21.5745648 , 21.91653509, 21.45790963,\n",
       "       21.36514617, 22.67691442, 18.87110923, 18.09304666, 19.54656433,\n",
       "       14.07338121, 19.20315592, 17.46722858, 15.61460268, 17.82141528,\n",
       "       16.28041677, 18.09777783, 17.63563011, 21.75440956, 22.83834076,\n",
       "       13.80885512, 19.97781172, 11.93381383, 15.87061896, 16.18996087,\n",
       "       22.26755867, 21.01427882, 22.39870055, 22.1647288 , 28.04540917,\n",
       "       30.86598651, 28.69181712, 25.88275245, 25.25750796, 23.65051871,\n",
       "       21.84161508, 20.28668284, 18.9120323 , 10.51585273, 18.55719878,\n",
       "       21.99924592, 24.58035353, 28.1782064 , 24.63058019, 18.37026561,\n",
       "       30.57921513, 27.12942798, 31.0659274 , 24.16478609, 22.16223876,\n",
       "       19.48769642, 19.68293983, 25.44389982, 25.24832713, 27.96924784,\n",
       "       28.06173263, 23.35077478, 23.02471218, 19.44977056, 22.71042492,\n",
       "       25.58258115, 22.23685568, 24.83216074, 24.49739645, 25.32893773,\n",
       "       24.28314825, 22.73213337, 23.06557395, 22.39195204, 22.63650433,\n",
       "       27.64155577, 26.26294062, 25.28840812, 24.36174671, 24.49492058,\n",
       "       26.95217409, 21.43810595, 24.04155944, 29.36506838, 29.54238751,\n",
       "       25.43095549, 25.69026678, 25.60757585, 25.68578384, 23.65830937,\n",
       "       27.11575326, 23.06753254, 33.98682873, 33.33548776, 30.47914408,\n",
       "       24.40569126, 25.48526686, 21.9172121 , 20.12771852, 20.79147996,\n",
       "       17.51635407, 16.373835  , 19.75276252, 22.01308148, 19.42891174,\n",
       "       20.56852245, 25.91914119, 19.8126868 , 20.07141264, 23.97946646,\n",
       "       19.99489795, 22.89726091, 23.16473193, 19.95967284, 20.39369335,\n",
       "       19.74129761, 20.28618045, 18.30291053, 14.16635119, 18.16233155,\n",
       "       19.96297037, 12.28626976, 16.35776121, 20.11412197, 15.57959853,\n",
       "       21.6005656 , 21.2628704 , 21.98481127, 17.92248726, 16.28891734,\n",
       "       18.95879745, 17.43683748, 20.5947871 , 14.94025546, 17.50691689,\n",
       "       14.74719824,  5.20886021, 14.50096581, 14.9509058 , 11.34134108,\n",
       "       16.38009279, 19.97042078, 11.30074726, 12.83791142, 17.82873133,\n",
       "       23.55040549, 21.12028298, 20.18445839, 20.89457138, 22.96810649,\n",
       "       22.64437536, 18.68758111, 31.42899019, 27.1060184 , 28.36619958,\n",
       "       28.24950907, 34.98196634, 36.12764805, 37.6449735 , 23.78054325,\n",
       "       25.33685665, 35.69417672, 23.28877529, 25.6517829 , 25.92873174,\n",
       "       22.27195585, 23.59412845, 19.99879975, 26.06488639, 23.60922699,\n",
       "       28.40112405, 23.99814553, 27.04055379, 28.82580341, 29.48917404,\n",
       "       31.26935883, 24.06712906, 30.26941083, 27.55933565, 19.71799448,\n",
       "       22.24474565, 33.06337863, 29.51833939, 29.67580925, 31.72291899,\n",
       "       30.92427334, 30.33227599, 32.93479846, 30.15798268, 29.6900975 ,\n",
       "       36.08384203, 34.38301057, 31.35269819, 33.06184216, 30.20522206,\n",
       "       30.85335536, 27.05955222, 34.8058399 , 35.39234097, 36.54951191,\n",
       "       21.88686713, 23.5147088 , 17.8833659 , 20.64225316, 13.70283993,\n",
       "       18.96754159, 13.48942936, 18.98741531, 24.47588346, 10.6619133 ,\n",
       "       23.7006351 , 21.92253077, 26.73450986, 19.98379953, 25.29424859,\n",
       "       27.2956987 , 18.42439377, 26.90550439, 27.06678343, 35.13233386,\n",
       "       36.65721753, 34.76498601, 29.74018806, 32.98459456, 28.68608349,\n",
       "       22.5559974 , 31.26210402, 36.23796898, 35.14115545, 27.18794318,\n",
       "       23.34116205, 26.13669396, 31.33927783, 27.61535386, 27.60556888,\n",
       "       26.7535576 , 23.15340567, 24.71276132, 27.84698174, 19.56627899,\n",
       "       16.68541402, 23.25110561, 23.18766839, 24.29792558, 26.9075798 ,\n",
       "       26.34747938, 27.26730256, 29.32124934, 34.3707482 , 26.22016504,\n",
       "       23.9967613 , 33.43942158, 39.08124843, 32.44262586, 31.00380945,\n",
       "       31.06492529, 33.43881836, 37.50035407, 30.7209865 , 31.80684711,\n",
       "       24.28578973, 27.73422148, 36.34539053, 35.2857928 , 20.60714245,\n",
       "       20.6772545 , 25.36179281, 25.94366844, 30.96359043, 29.5052516 ,\n",
       "       30.14952872, 30.20600986, 29.44835355, 26.62046236, 30.73562237,\n",
       "       35.15451626, 31.45853033, 34.83023529, 36.67454486, 30.05965409,\n",
       "       27.41625295, 22.31289104, 26.21119318, 26.39247032, 26.3602364 ,\n",
       "       29.00881624, 30.00400643, 27.43539734, 25.55170515, 24.19158952,\n",
       "       28.82900548, 27.76601509, 20.64303312, 28.87603917, 31.68736567,\n",
       "       30.40786919, 26.820124  , 26.84105683, 30.62952351, 29.16091385,\n",
       "       25.77022548, 30.10705092, 27.37329989, 28.03116089, 22.76993319,\n",
       "       17.49118293, 25.33287309, 22.09799212, 24.928913  , 25.41159253,\n",
       "       20.97823938, 18.3824152 , 19.07154359, 24.15907896, 21.94410168,\n",
       "       25.15660843, 25.12723559, 23.42000588, 20.11468717, 25.65051104,\n",
       "       26.2225287 , 25.23745303, 21.05421362, 23.2723399 , 26.36179386,\n",
       "       24.74881426, 21.44723217, 24.92528984, 25.09936991, 24.54410385,\n",
       "       22.87784589, 21.33935067, 21.05822596, 22.71303674, 21.81756222,\n",
       "       21.97535704, 31.6990764 , 27.16178303, 27.45266875, 29.39951976,\n",
       "       22.38462889, 20.83157889, 26.96891413, 28.16882577, 27.71421827,\n",
       "       25.94784725, 27.35312898, 23.56690517, 29.25553706, 20.26609472,\n",
       "       22.53978164, 18.75304334, 21.63811626, 21.49932248, 20.84097303,\n",
       "       24.33827676, 20.54378317, 19.15381667, 18.59322388, 34.74816977,\n",
       "       13.66493292, 15.59056602, 11.30490225, 21.07009905, 27.45805984,\n",
       "       29.16093069, 22.75381147, 21.72223902,  5.21444531,  0.65625533,\n",
       "       25.1133361 , 17.61180038, 19.2329118 , 16.41566289, 16.75116945,\n",
       "       21.90718429, 18.34984637, 13.19779415, 12.65912291,  4.97067169,\n",
       "        8.61547379,  7.45609406,  6.95860798,  7.12762139, 13.99931091,\n",
       "       17.10061806, 17.55581116, 10.23187818, 19.92458612, 18.15561776,\n",
       "       20.02091891, 18.65800006, 15.83371336,  9.4050919 , 11.13887115,\n",
       "       13.36667754, 17.94647787, 18.14599779, 14.37724536, 11.1671753 ,\n",
       "       14.05031538,  7.86988223, 19.04455425, 11.95696872, 19.75066768,\n",
       "       19.97010909, 17.99532068,  3.60812543, 13.10444554,  2.00842853,\n",
       "       13.22873906, 16.18190669, 10.25625163, 15.55050678, 17.91249585,\n",
       "       20.68673607, 18.78585778, 18.14026653, 14.76108701, 15.7283378 ,\n",
       "       13.42478651, 17.55158097, 19.53208599, 16.1750508 , 15.5549483 ,\n",
       "       18.67502493, 19.52742448, 21.78787161, 19.75371014, 19.39474874,\n",
       "       17.01727971, 18.79716701, 13.39445571,  8.91399297, 13.9071804 ,\n",
       "       15.01714841, 18.56565654, 19.31739256, 19.2053488 , 14.02241625,\n",
       "       15.87496128, 19.0388466 , 19.50136948, 18.42346145, 18.5502849 ,\n",
       "       20.15953439, 20.35641423, 19.26012997, 23.74178531, 19.4601802 ,\n",
       "       19.05131746, 16.41177785, 17.27145132, 19.56818687, 19.72508223,\n",
       "       20.98636843, 20.87941733, 20.99001433, 23.57931178, 20.9549796 ,\n",
       "       18.63946558, 17.26572148, 16.00530792, 17.3663982 , 18.27273818,\n",
       "       19.26778856, 21.20301791, 21.26310819, 24.66611012, 15.40043171,\n",
       "       15.18253774, 19.30472936, 11.55622623, 18.4390043 , 21.05998379,\n",
       "       22.31433362, 25.76052943, 27.32970051, 20.60988705, 19.53687916,\n",
       "       22.64796811, 19.70520145, 20.64175364, 15.6910018 , 12.49967772,\n",
       "        8.37189156, 17.72105935, 20.07890391, 20.23664623, 20.29844494,\n",
       "       17.3099641 , 14.47647763, 19.5348736 , 20.99072793, 18.1661813 ,\n",
       "       20.3213211 , 23.69591134, 22.17026849, 27.18783712, 26.06023305,\n",
       "       22.41839098])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importantly -- this will invoke all the processing steps before predicting!\n",
    "pipe.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jonat\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this means you could take your random forest, and use it like you normally would, without having\n",
    "# to create a separate dataset\n",
    "rfc.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
